{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea420288",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction from Clinical Data\n",
    "\n",
    "This project addresses a **classic binary classification problem in the medical field**: predicting whether a patient has heart disease or not, based on a set of clinical variables obtained during routine check-ups.\n",
    "\n",
    "We will work with a **dataset consisting of 918 observations**, where each row represents a different patient and the columns contain medical information such as:\n",
    "\n",
    "- **Age**\n",
    "- **Resting Blood Pressure (RestingBP)**\n",
    "- **Serum Cholesterol (Cholesterol)**\n",
    "- **Resting Electrocardiogram Results (RestingECG)**\n",
    "- **Exercise-related indicators** such as Maximum Heart Rate (MaxHR), ST segment depression (Oldpeak), and Exercise-Induced Angina (ExerciseAngina)\n",
    "- **Categorical features** such as Chest Pain Type (ChestPainType)\n",
    "- **Target variable:** `HeartDisease`, which indicates whether the patient has (1) or does not have (0) heart disease.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Project Objective\n",
    "\n",
    "The main goal is to **build a predictive model** capable of detecting the presence of heart disease with a balanced performance between **precision** and **recall**.\n",
    "\n",
    "Beyond the model itself, the educational objective is to **explain step by step** the typical workflow in a *Machine Learning project applied to healthcare*, so that anyone can:\n",
    "- Understand the process,\n",
    "- Reproduce the results,\n",
    "- And apply the methodology to other clinical datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## üßæ Variable Dictionary\n",
    "\n",
    "| Variable | Type | Description |\n",
    "|:----------|:------|:-------------|\n",
    "| **Age** | Numeric | Patient‚Äôs age (in years). |\n",
    "| **Sex** | Categorical | Patient‚Äôs sex: `M` (male), `F` (female). |\n",
    "| **ChestPainType** | Categorical | Type of chest pain:<br> - `TA`: Typical angina<br> - `ATA`: Atypical angina<br> - `NAP`: Non-anginal pain<br> - `ASY`: Asymptomatic. |\n",
    "| **RestingBP** | Numeric | Resting blood pressure (mm Hg). |\n",
    "| **Cholesterol** | Numeric | Serum cholesterol (mg/dl). |\n",
    "| **FastingBS** | Binary | Fasting blood sugar > 120 mg/dl:<br> - `1`: Yes<br> - `0`: No. |\n",
    "| **RestingECG** | Categorical | Resting electrocardiogram results:<br> - `Normal`<br> - `ST`: ST-T wave abnormality<br> - `LVH`: Left ventricular hypertrophy. |\n",
    "| **MaxHR** | Numeric | Maximum heart rate achieved. |\n",
    "| **ExerciseAngina** | Binary | Exercise-induced angina:<br> - `Y`: Yes<br> - `N`: No. |\n",
    "| **Oldpeak** | Numeric | ST depression induced by exercise relative to rest. |\n",
    "| **ST_Slope** | Categorical | Slope of the ST segment during exercise:<br> - `Up`: Upsloping<br> - `Flat`: Flat<br> - `Down`: Downsloping. |\n",
    "| **HeartDisease** | Binary | Target variable:<br> - `1`: Presence of heart disease<br> - `0`: Absence of heart disease. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2992550",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßæ Index\n",
    "\n",
    "This notebook follows a structured workflow with the goal of illustrating **all the phases of a Machine Learning project**, from data exploration to final model evaluation.  \n",
    "The complete process is divided into the following stages:\n",
    "\n",
    "- **Phase 0:** Environment Setup  \n",
    "- **Phase 1:** Dataset Loading and Initial Review  \n",
    "- **Phase 2:** Exploratory Data Analysis (EDA)  \n",
    "- **Phase 3:** Feature Engineering and Encoding  \n",
    "- **Phase 4:** Model Training and Comparison  \n",
    "- **Phase 5:** Hyperparameter Tuning and Optimal Model Selection  \n",
    "- **Phase 6:** Conclusions and Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b213f654",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Phase 0: Environment Setup\n",
    "\n",
    "Before starting any analysis, it is essential to **prepare the working environment**.  \n",
    "This includes:\n",
    "\n",
    "- Importing the necessary libraries  \n",
    "- Setting up visualization options  \n",
    "- Documenting from the very first code block  \n",
    "\n",
    "üéØ **Objective of this phase:**  \n",
    "Get the environment ready for analysis, making it explicit which tools will be used and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202abc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistics and hypothesis testing\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, mannwhitneyu\n",
    "\n",
    "# Preprocessing, modeling, and evaluation (Machine Learning)\n",
    "import joblib  # Saving and loading trained models\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import (\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    RocCurveDisplay,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "# Model explainability\n",
    "import shap\n",
    "\n",
    "# General environment configuration\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress non-critical warnings\n",
    "\n",
    "# Display plots inside the notebook\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"whitegrid\")  # Define consistent visual style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc72118f",
   "metadata": {},
   "source": [
    "## üì• Phase 1: Dataset Loading and Initial Review\n",
    "\n",
    "In this phase, we begin data analysis by importing the dataset that will serve as the foundation for our predictive model.  \n",
    "The main goal is to **understand the overall structure of the dataset** before applying any transformations.\n",
    "\n",
    "üéØ Objective of this phase\n",
    "\n",
    "- Load the data from the corresponding source (CSV, database, etc.).  \n",
    "- Explore the **dataset dimensions** (rows and columns).  \n",
    "- Identify the **type of each variable** (numerical, categorical, or binary).  \n",
    "- Detect **null or missing values**.  \n",
    "- Observe possible inconsistencies or initial data errors.\n",
    "\n",
    "This step is essential to obtain a **broad overview of the dataset** and plan the subsequent data cleaning and preprocessing stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a14edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"heart.csv\")  # Make sure the file is in the same directory\n",
    "\n",
    "# Display dataset dimensions (rows, columns)\n",
    "print(f\"Dataset dimensions: {df.shape[0]} rows and {df.shape[1]} columns\\n\")\n",
    "\n",
    "# Preview the first few records\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a24f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General dataset information: data types, non-null counts, and memory usage\n",
    "df.info()\n",
    "\n",
    "# Count of null values per column (to detect missing data)\n",
    "print(\"\\nNull values per column:\\n\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Count of unique values per column (useful to distinguish categorical and numerical variables)\n",
    "print(\"\\nUnique values per column:\\n\")\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875d63a5",
   "metadata": {},
   "source": [
    "## üîç Phase 2: Exploratory Data Analysis (EDA)\n",
    "\n",
    "Exploratory Data Analysis (EDA) is one of the most important stages in any Machine Learning project.  \n",
    "Its main goal is to **thoroughly understand the nature of the data** before applying transformations or building predictive models.\n",
    "\n",
    "Unlike modeling, here we are not trying to predict anything ‚Äî we aim to **understand, detect patterns, inconsistencies, and relationships** among variables.\n",
    "\n",
    "üéØ General Objective of this Phase\n",
    "\n",
    "- Analyze the shape, behavior, and relationships among variables.  \n",
    "- Identify outliers, skewed distributions, and strong correlations.  \n",
    "- Determine which variables should be cleaned, transformed, or removed.  \n",
    "\n",
    "In summary: this is the stage where **key decisions are made** that will determine the quality of the subsequent modeling.\n",
    "\n",
    "---\n",
    "\n",
    "üß≠ EDA Subphases\n",
    "\n",
    "üîπ **EDA 1 ‚Äî Univariate Analysis (variable by variable)**  \n",
    "Variables are analyzed individually to understand their distribution and basic characteristics:\n",
    "\n",
    "- Are they symmetric or skewed?  \n",
    "- Do they contain outliers?  \n",
    "- Are they discrete or continuous?  \n",
    "\n",
    "\n",
    "üîπ **EDA 2 ‚Äî Bivariate Analysis with the Target Variable (`HeartDisease`)**  \n",
    "Here we explore how the predictor variables relate to the target variable, looking for patterns that help generate hypotheses:\n",
    "\n",
    "- Are there variables that clearly differentiate between classes?  \n",
    "- What kind of relationship do they have with the *target*?  \n",
    "\n",
    "\n",
    "üîπ **EDA 3 ‚Äî Target Variable Analysis: `HeartDisease`**  \n",
    "Here we analyze the target variable by itself.\n",
    "\n",
    "- Is it balanced?  \n",
    "- Do we need to apply resampling techniques?  \n",
    "- What metrics should we use to evaluate the model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371317e7",
   "metadata": {},
   "source": [
    "---\n",
    "### üîç EDA 1: Univariate Analysis\n",
    "\n",
    "#### üìò EDA 1.1: Univariate Analysis of Numerical Variables\n",
    "\n",
    "We start with the **numerical variables** to examine:\n",
    "\n",
    "- Their distributions (symmetry, skewness, long tails).  \n",
    "- Presence of outliers.  \n",
    "- Possible need for scaling or transformation.\n",
    "\n",
    "In this first stage, we will visualize each numerical variable using **histograms** (to observe the shape of the distribution) and **boxplots** (to detect possible outliers)\n",
    "\n",
    "These visualizations allow us to identify patterns, skews, and anomalies that may influence the preprocessing and modeling stages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b415166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical variables, excluding the target variable (HeartDisease)\n",
    "numerical_variables = df.select_dtypes(include=[\"int64\", \"float64\"]).drop(columns=[\"HeartDisease\"])\n",
    "\n",
    "# Loop through each numerical variable to analyze its distribution and possible outliers\n",
    "for col in numerical_variables.columns:\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "    \n",
    "    # Histogram with density curve\n",
    "    sns.histplot(data=df, x=col, kde=True, color=\"steelblue\", ax=axs[0])\n",
    "    axs[0].set_title(f\"Distribution of {col}\", fontsize=11)\n",
    "    axs[0].set_xlabel(col)\n",
    "    axs[0].set_ylabel(\"Frequency\")\n",
    "    \n",
    "    # Boxplot for visual detection of outliers\n",
    "    sns.boxplot(data=df, x=col, color=\"lightcoral\", ax=axs[1])\n",
    "    axs[1].set_title(f\"Boxplot of {col}\", fontsize=11)\n",
    "    axs[1].set_xlabel(col)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14677fde",
   "metadata": {},
   "source": [
    "**Results Analysis**\n",
    "\n",
    "After visualizing the numerical variables, we analyzed their individual behavior, distribution, and clinical plausibility.  \n",
    "The goal is to decide which transformations or actions should be taken before modeling.\n",
    "\n",
    "---\n",
    "\n",
    "üîπ 1. Age  \n",
    "- **Distribution:** Approximately normal, with slight negative skewness.  \n",
    "- **Boxplot:** No outliers observed.  \n",
    "- **Range:** Minimum ~28 years, maximum ~77 years ‚Üí clinically plausible values.  \n",
    "- **Action:** Keep unchanged. May be normalized if using models sensitive to scale (SVM, KNN, MLP).\n",
    "\n",
    "üîπ 2. RestingBP (Resting Blood Pressure)  \n",
    "- **Distribution:** Positively skewed. Higher concentration between 110‚Äì150 mmHg, peak around 120.  \n",
    "- **Boxplot:** Outliers on both ends.  \n",
    "- **Range:** Minimum = 0 ‚Üí physiologically impossible.  \n",
    "- **Suggested action:**  \n",
    "  - Review and remove/impute zero values.  \n",
    "  - Consider logarithmic transformation or robust trimming if using linear or scale-sensitive models.\n",
    "\n",
    "üîπ 3. Cholesterol  \n",
    "- **Distribution:** Strongly positively skewed. Abnormal peak at 0.  \n",
    "- **Boxplot:** Outliers between 400‚Äì600 mg/dL.  \n",
    "- **Range:** Minimum = 0 ‚Üí medically implausible.  \n",
    "- **Suggested action:**  \n",
    "  - Treat zeros as missing or erroneous values.  \n",
    "  - Consider logarithmic transformation to correct skewness.  \n",
    "  - Handle outliers if using sensitive models (e.g., logistic regression).\n",
    "\n",
    "üîπ 4. FastingBS (Fasting Blood Sugar >120 mg/dL)  \n",
    "- **Distribution:** Binary variable (0 or 1).  \n",
    "- **Boxplot:** Not applicable for binary variables.  \n",
    "- **Approximate count:** 700 values = 0, 218 values = 1 ‚Üí slight imbalance.  \n",
    "- **Suggested action:**  \n",
    "  - Treat as categorical/bool variable.  \n",
    "  - No transformation required.  \n",
    "  - Can remain as integer if supported by the models.\n",
    "\n",
    "üîπ 5. MaxHR (Maximum Heart Rate Achieved)  \n",
    "- **Distribution:** Nearly symmetric, with slight negative skewness.  \n",
    "- **Boxplot:** Few outliers.  \n",
    "- **Range:** 60‚Äì200 bpm ‚Üí clinically plausible.  \n",
    "- **Suggested action:**  \n",
    "  - Ready for modeling.  \n",
    "  - Scale if using algorithms sensitive to magnitude.\n",
    "\n",
    "üîπ 6. Oldpeak (ST Segment Depression)  \n",
    "- **Distribution:** Strongly positively skewed, with high concentration at 0 and long right tail.  \n",
    "- **Boxplot:** Visible outliers; presence of negative values that may be errors.  \n",
    "- **Suggested action:**  \n",
    "  - Verify negative values ‚Äî may be incorrect.  \n",
    "  - Apply logarithmic or square root transformation to reduce skewness.  \n",
    "  - Can remain untransformed for tree-based models.\n",
    "\n",
    "Overall, this analysis helps **define the cleaning and preprocessing strategies** for numerical variables before modeling:  \n",
    "- Correction of impossible values (RestingBP and Cholesterol).  \n",
    "- Optional transformation for skewed variables (Oldpeak, Cholesterol).  \n",
    "- Possible normalization or scaling if using magnitude-sensitive models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bc5467",
   "metadata": {},
   "source": [
    "---\n",
    "#### üß© EDA 1.2: Univariate Analysis of Categorical Variables\n",
    "\n",
    "After analyzing the numerical variables, we move on to the study of **categorical variables**.  \n",
    "This part is essential to understand **how categories are distributed**, whether there are **imbalanced classes** or **inconsistent encodings**, and how to **prepare them for modeling**.\n",
    "\n",
    "üéØ Objective\n",
    "\n",
    "In this subphase, the goal is to:\n",
    "\n",
    "- Analyze the **frequency of each category** in qualitative variables (`Sex`, `ChestPainType`, `RestingECG`, `ExerciseAngina`, `ST_Slope`, etc.).  \n",
    "- Detect **encoding errors** or atypical categories.  \n",
    "- Evaluate whether there are **highly imbalanced classes** that could affect model learning.  \n",
    "- Decide the most suitable **encoding strategy**:\n",
    "  - *One-Hot Encoding* for variables without inherent order.\n",
    "  - *Label Encoding* for those with a natural or ordinal hierarchy.\n",
    "- Identify **rare or dominant categories** that could distort the model representation.\n",
    "\n",
    "Properly analyzing categorical variables allows for the definition of a **robust encoding strategy** and helps prevent bias or information loss in later preprocessing stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f325ad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical variables from the dataset\n",
    "categorical = df.select_dtypes(include=\"object\")\n",
    "\n",
    "# Loop through each categorical variable to visualize its frequency distribution\n",
    "for col in categorical.columns:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    \n",
    "    # Bar plot ordered by frequency\n",
    "    sns.countplot(\n",
    "        data=df,\n",
    "        x=col,\n",
    "        order=df[col].value_counts().index,\n",
    "        palette=\"pastel\"\n",
    "    )\n",
    "    \n",
    "    plt.title(f\"Category Frequency in {col}\", fontsize=11)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d04c78",
   "metadata": {},
   "source": [
    "**Results Analysis**\n",
    "\n",
    "In this stage, we analyzed the categorical variables to understand how their classes are distributed, identify possible encoding issues, and decide on the best representation strategy for modeling.\n",
    "\n",
    "---\n",
    "\n",
    "üîπ **Sex**  \n",
    "- **Classes:** `M` (majority), `F` (minority).  \n",
    "- **Distribution:** Moderately imbalanced (approx. 75% male, 25% female).  \n",
    "- **Encoding:** Correct, clear, and standard (`M`, `F`).  \n",
    "- **Decisions:**  \n",
    "  - Encode as binary (`M` ‚Üí 1, `F` ‚Üí 0).  \n",
    "  - Alternatively, apply *One-Hot Encoding* (though it will only generate one extra column).  \n",
    "  - Variable suitable for direct use after encoding.\n",
    "\n",
    "---\n",
    "\n",
    "üîπ **ChestPainType**  \n",
    "- **Classes:**  \n",
    "  - `ASY` ‚Üí dominant  \n",
    "  - `NAP`  \n",
    "  - `ATA`  \n",
    "  - `TA`  \n",
    "- **Distribution:** Slightly imbalanced, but all classes are represented.  \n",
    "- **Decisions:**  \n",
    "  - **Nominal** variable (no inherent order).  \n",
    "  - Apply *One-Hot Encoding* to prevent the model from assuming nonexistent relationships among categories.\n",
    "\n",
    "---\n",
    "\n",
    "üîπ **RestingECG** (Resting Electrocardiogram)  \n",
    "- **Classes:**  \n",
    "  - `Normal` ‚Üí dominant (~60%)  \n",
    "  - `LVH` ‚Üí left ventricular hypertrophy  \n",
    "  - `ST` ‚Üí ST segment abnormality  \n",
    "- **Distribution:** Slightly imbalanced but all classes have sufficient representation.  \n",
    "- **Decisions:**  \n",
    "  - **Nominal** variable (no inherent order).  \n",
    "  - Apply *One-Hot Encoding* to prevent the model from interpreting nonexistent relationships between categories.\n",
    "\n",
    "---\n",
    "\n",
    "üîπ **ExerciseAngina** (Exercise-Induced Angina)  \n",
    "- **Classes:** `N` (majority), `Y` (minority).  \n",
    "- **Distribution:** Moderately imbalanced.  \n",
    "- **Encoding:** Binary text (`Y` / `N`).  \n",
    "- **Decisions:**  \n",
    "  - Encode as binary (`Y` ‚Üí 1, `N` ‚Üí 0).  \n",
    "  - Does not require *One-Hot Encoding* or additional transformations.\n",
    "\n",
    "---\n",
    "\n",
    "üîπ **ST_Slope** (ST Segment Slope)  \n",
    "- **Classes:**  \n",
    "  - `Flat` ‚Üí most frequent  \n",
    "  - `Up` ‚Üí second most frequent  \n",
    "  - `Down` ‚Üí least frequent  \n",
    "- **Distribution:** Moderately imbalanced.  \n",
    "- **Clinical note:**  \n",
    "  In cardiology, `Up` is generally associated with a healthy exercise response, while `Flat` and `Down` may indicate higher risk.  \n",
    "- **Decisions:**  \n",
    "  - **Ordinal** variable, so a numerical encoding preserving the semantic order can be used:  \n",
    "    `Down` = 0, `Flat` = 1, `Up` = 2  \n",
    "  - This representation may help linear models.  \n",
    "  - If the true order is uncertain, apply *One-Hot Encoding* (especially recommended for tree-based models).\n",
    "\n",
    "---\n",
    "\n",
    "Analyzing the categorical variables allows for **a coherent and bias-free encoding plan**, ensuring that qualitative information is interpreted correctly by Machine Learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dc6786",
   "metadata": {},
   "source": [
    "### üß© EDA 2 ‚Äî Bivariate Analysis with the Target Variable (`HeartDisease`)\n",
    "\n",
    "In this second part of the exploratory analysis, we examine how the independent variables (both numerical and categorical) relate to the **target variable `HeartDisease`**.  \n",
    "This step is crucial to identify **predictive patterns** and **significant relationships** that will guide the later modeling stages.\n",
    "\n",
    "---\n",
    "\n",
    "üéØ **Objective of this phase**\n",
    "\n",
    "- Evaluate the relationship between patient characteristics and the presence or absence of heart disease.  \n",
    "- Detect **variables with discriminative power** with respect to the *target*.  \n",
    "- Identify **statistically significant relationships** between predictor variables and the target variable.  \n",
    "- Begin defining which variables should be included, transformed, or discarded before model training.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìò EDA 2.1 ‚Äî Bivariate Analysis of Numerical Variables\n",
    "\n",
    "In this section, we analyze how **numerical variables** behave depending on the value of `HeartDisease` (`0` = no disease, `1` = heart disease).\n",
    "\n",
    "For each variable:\n",
    "\n",
    "- **Boxplots** will be shown to compare both groups, allowing us to visualize distribution differences.  \n",
    "- **Non-parametric statistical tests** (such as *Mann‚ÄìWhitney U*) will be applied to verify whether the observed differences are **statistically significant**.  \n",
    "\n",
    "This approach combines **visual and analytical analysis**, helping to identify variables that truly differentiate between healthy patients and those with heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41458d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical variables excluding the target variable\n",
    "num_vars = df.select_dtypes(include=[\"int64\", \"float64\"]).drop(columns=[\"HeartDisease\"]).columns\n",
    "\n",
    "# Compare each numerical variable against the target variable HeartDisease\n",
    "for col in num_vars:\n",
    "    # Comparative visualization using boxplot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(\n",
    "        data=df,\n",
    "        x=\"HeartDisease\",\n",
    "        y=col,\n",
    "        palette=\"Set2\"\n",
    "    )\n",
    "    plt.title(f\"{col} vs HeartDisease\", fontsize=11)\n",
    "    plt.xlabel(\"HeartDisease (0 = No, 1 = Yes)\")\n",
    "    plt.ylabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Separate values according to target class\n",
    "    group_0 = df[df[\"HeartDisease\"] == 0][col]\n",
    "    group_1 = df[df[\"HeartDisease\"] == 1][col]\n",
    "\n",
    "    # Mann‚ÄìWhitney U test (non-parametric)\n",
    "    stat, p_value = mannwhitneyu(group_0, group_1, alternative=\"two-sided\")\n",
    "\n",
    "    # Test results\n",
    "    print(f\"‚û§ Mann‚ÄìWhitney Test for {col}\")\n",
    "    print(f\"   U Statistic = {stat:.2f}\")\n",
    "    print(f\"   p-value = {p_value:.4f}\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"   ‚Üí Significant difference between groups (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"   ‚Üí No significant difference detected (p ‚â• 0.05)\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74049d5e",
   "metadata": {},
   "source": [
    "**Results Analysis**\n",
    "\n",
    "After comparing the numerical variables against the target variable `HeartDisease`, we analyzed the results in terms of distribution, statistical significance, and clinical implications.\n",
    "\n",
    "---\n",
    "\n",
    "üîπ **Age**  \n",
    "- **Boxplot:** Patients with heart disease tend to be older.  \n",
    "- **p-value:** 0.0000 ‚Üí statistically significant difference.  \n",
    "- **Interpretation:** Age is clearly related to the presence of heart disease, consistent with medical evidence.  \n",
    "- **Decision:** Include in the model without modification.\n",
    "\n",
    "---\n",
    "\n",
    "üîπ **RestingBP** (Resting Blood Pressure)  \n",
    "- **Boxplot:** Similar groups with a slight visual difference.  \n",
    "- **p-value:** 0.0006 ‚Üí significant difference, though subtle.  \n",
    "- **Interpretation:** May provide some information, but the effect is mild. Also, the zero values must be reviewed.  \n",
    "- **Decision:** Correct zeros and consider transformation or robust scaling before inclusion.\n",
    "\n",
    "---\n",
    "\n",
    "üîπ **Cholesterol**  \n",
    "- **Boxplot:** High dispersion, especially in patients with disease. Notable presence of outliers.  \n",
    "- **p-value:** 0.0000 ‚Üí highly significant.  \n",
    "- **Interpretation:** Patients with heart disease show more variable and elevated cholesterol levels, although anomalous zeros distort the analysis.  \n",
    "- **Decision:** Treat zeros as missing values, possibly apply logarithmic transformation. Potentially useful variable after cleaning.\n",
    "\n",
    "---\n",
    "\n",
    "üîπ **FastingBS** (Fasting Blood Sugar >120 mg/dL)  \n",
    "- **Boxplot:** Much more frequent in patients with disease.  \n",
    "- **p-value:** 0.0000 ‚Üí very significant.  \n",
    "- **Interpretation:** Fasting hyperglycemia is a known risk factor for heart disease.  \n",
    "- **Decision:** Highly informative binary categorical variable. Include directly.\n",
    "\n",
    "---\n",
    "\n",
    "üîπ **MaxHR** (Maximum Heart Rate Achieved)  \n",
    "- **Boxplot:** Patients without heart disease reach higher heart rates.  \n",
    "- **p-value:** 0.0000 ‚Üí clear and significant difference.  \n",
    "- **Interpretation:** The ability to reach higher heart rates indicates better cardiac function.  \n",
    "- **Decision:** Strong predictive variable. Include in the model.\n",
    "\n",
    "---\n",
    "\n",
    "üîπ **Oldpeak** (ST Segment Depression)  \n",
    "- **Boxplot:** Patients with heart disease show higher and more dispersed values.  \n",
    "- **p-value:** 0.0000 ‚Üí very significant.  \n",
    "- **Interpretation:** Oldpeak measures ST depression during exercise; higher values often indicate worse cardiac condition.  \n",
    "- **Decision:** Highly informative variable, but requires skewness treatment (log or robust scaling).\n",
    "\n",
    "---\n",
    "\n",
    "Overall, all numerical variables show **some degree of significant relationship with `HeartDisease`**, reinforcing their predictive value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841cd8ba",
   "metadata": {},
   "source": [
    "#### üß© EDA 2.2 ‚Äî Bivariate Analysis: Categorical Variables vs. `HeartDisease`\n",
    "\n",
    "In this subphase, we explore how **categorical variables** relate to the target variable `HeartDisease`.  \n",
    "The goal is to identify categories that show differential patterns between patients with and without heart disease.\n",
    "\n",
    "üéØ **Objective**\n",
    "\n",
    "- Evaluate whether there is a **statistical association** between categorical variables (`Sex`, `ChestPainType`, `RestingECG`, `ExerciseAngina`, `ST_Slope`) and the presence of heart disease.  \n",
    "- Determine which categorical variables are potentially **predictive**.  \n",
    "- Support the decision to **retain, transform, or discard** variables before modeling.\n",
    "\n",
    "---\n",
    "\n",
    "**Methodology:**\n",
    "  - Crossed bar charts  \n",
    "  - Chi-Square (œá¬≤) Test of Independence  \n",
    "\n",
    "üéØ **Purpose**\n",
    "\n",
    "The Chi-Square test allows us to verify whether there is a **statistical dependency** between two categorical variables.  \n",
    "In this case, between a categorical variable (e.g., `ChestPainType`) and `HeartDisease`.\n",
    "\n",
    "---\n",
    "\n",
    "**Test Hypotheses**\n",
    "\n",
    "- **H‚ÇÄ (Null Hypothesis):** The variables are independent (no relationship).  \n",
    "- **H‚ÇÅ (Alternative Hypothesis):** The variables are not independent (there is a relationship).  \n",
    "\n",
    "---\n",
    "\n",
    "**Interpretation of p-value**\n",
    "\n",
    "- **If p < 0.05:** Reject H‚ÇÄ ‚Üí There is statistical dependence ‚Üí The categorical variable is related to `HeartDisease`.  \n",
    "- **If p ‚â• 0.05:** Fail to reject H‚ÇÄ ‚Üí No evidence of relationship ‚Üí The variable may not provide relevant predictive information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d078f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical variables from the dataset\n",
    "cat_vars = df.select_dtypes(include=\"object\").columns\n",
    "\n",
    "# Analyze each categorical variable against the target variable HeartDisease\n",
    "for col in cat_vars:\n",
    "    # Visualization: grouped bar chart by disease presence\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(\n",
    "        data=df,\n",
    "        x=col,\n",
    "        hue=\"HeartDisease\",\n",
    "        order=df[col].value_counts().index,\n",
    "        palette=\"Set2\"\n",
    "    )\n",
    "    plt.title(f\"{col} vs HeartDisease\", fontsize=11)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend(title=\"HeartDisease\", labels=[\"No (0)\", \"Yes (1)\"])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Contingency table (observed frequencies)\n",
    "    contingency = pd.crosstab(df[col], df[\"HeartDisease\"])\n",
    "\n",
    "    # Chi-square test of independence\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency)\n",
    "\n",
    "    # Test results\n",
    "    print(f\"‚û§ Chi-Square Test for {col}\")\n",
    "    print(f\"   œá¬≤ = {chi2:.2f} | p-value = {p_value:.4f}\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"   ‚Üí Significant association with HeartDisease (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"   ‚Üí No significant association detected (p ‚â• 0.05)\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bff155e",
   "metadata": {},
   "source": [
    "**Results Analysis**\n",
    "\n",
    "After analyzing the categorical variables against the target variable `HeartDisease`, the following summarizes the observations obtained from the bar charts and Chi-Square (œá¬≤) independence tests, along with their clinical interpretation and suggested modeling decisions.\n",
    "\n",
    "---\n",
    "\n",
    "üîπ **Sex**  \n",
    "- **Chart:** Among males (`M`), there are more heart disease cases, while among females (`F`), healthy cases are more prevalent.  \n",
    "- **p-value:** 0.0000 ‚Üí highly significant difference.  \n",
    "- **Interpretation:** Sex is a relevant predictive factor; the risk of heart disease is considerably higher in men, consistent with clinical evidence.  \n",
    "- **Decision:** Encode as binary (`M` = 1, `F` = 0).\n",
    "\n",
    "---\n",
    "\n",
    "üîπ **ChestPainType**  \n",
    "- **Chart:** The `ASY` chest pain type is strongly associated with heart disease, while `ATA` is more common among healthy patients.  \n",
    "- **p-value:** 0.0000 ‚Üí very strong and statistically significant difference.  \n",
    "- **Interpretation:** One of the strongest clinical predictors. Chest pain types directly reflect the likelihood of heart disease.  \n",
    "- **Decision:** Encode using *One-Hot Encoding* (a **nominal** variable with no inherent order).\n",
    "\n",
    "---\n",
    "\n",
    "üîπ **RestingECG** (Resting Electrocardiogram)  \n",
    "- **Chart:** The `ST` category shows a higher proportion of patients with heart disease.  \n",
    "- **p-value:** 0.0042 ‚Üí significant, though more moderate difference.  \n",
    "- **Interpretation:** May not be a strong standalone predictor but could complement other physiological variables in multivariate models.  \n",
    "- **Decision:** Encode using *One-Hot Encoding*. Do not treat as ordinal since there is no clear clinical order among categories (`Normal`, `ST`, `LVH`).\n",
    "\n",
    "---\n",
    "\n",
    "üîπ **ExerciseAngina** (Exercise-Induced Angina)  \n",
    "- **Chart:** Patients with `Y` (yes, angina induced by exercise) show a much higher proportion of heart disease, while those with `N` are mostly healthy.  \n",
    "- **p-value:** 0.0000 ‚Üí clear and highly significant difference.  \n",
    "- **Interpretation:** Exercise-induced angina is a direct clinical indicator of heart disease.  \n",
    "- **Decision:** Encode as binary (`Y` = 1, `N` = 0). Highly predictive variable.\n",
    "\n",
    "---\n",
    "\n",
    "üîπ **ST_Slope** (ST Segment Slope)  \n",
    "- **Chart:** The `Flat` category dominates among diseased patients, `Up` among healthy ones, and `Down` appears less frequently (indicating higher risk).  \n",
    "- **p-value:** 0.0000 ‚Üí highly significant difference.  \n",
    "- **Interpretation:** Clinically relevant variable. The order `Down < Flat < Up` represents a physiological gradient (from worse to better cardiac response to stress).  \n",
    "- **Decision:** Encode ordinally (`Down` = 0, `Flat` = 1, `Up` = 2) for linear models, or with *One-Hot Encoding* for tree-based models.\n",
    "\n",
    "---\n",
    "\n",
    "Overall, the categorical variables show **statistically significant associations** with `HeartDisease`, confirming their predictive value.  \n",
    "Particularly strong predictors include **`ChestPainType`**, **`ExerciseAngina`**, and **`ST_Slope`**, both for their statistical significance and clinical relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e710d204",
   "metadata": {},
   "source": [
    "### ‚úÖ EDA 3 ‚Äî Target Variable Analysis: `HeartDisease`\n",
    "\n",
    "Before training any model, it is essential to **analyze the target variable (`HeartDisease`) on its own**, even if we have already used it in the bivariate analysis.  \n",
    "Understanding its distribution and class balance allows us to design a fairer and more robust modeling process.\n",
    "\n",
    "---\n",
    "\n",
    "üéØ **Why analyze `HeartDisease` directly?**\n",
    "\n",
    "Although `HeartDisease` has already been used to evaluate relationships with other variables, we now examine it independently to answer key questions:\n",
    "\n",
    "- **Is it balanced?**  \n",
    "  Is there a similar proportion of patients with (`1`) and without (`0`) heart disease?  \n",
    "  A significant imbalance may bias the model toward the majority class.\n",
    "\n",
    "- **What does its distribution imply?**  \n",
    "  The class ratio influences:\n",
    "  - The choice of **evaluation metrics** (e.g., *F1-score*, *ROC-AUC*, *Recall*).  \n",
    "  - The need to **adjust class weights** or apply balancing techniques such as *oversampling* or *SMOTE*.  \n",
    "  - The type of **validation** used (*stratified k-fold* is preferable to maintain class proportions).\n",
    "\n",
    "---\n",
    "\n",
    "üîç **What is considered class imbalance?**\n",
    "\n",
    "| Approximate ratio | Requires correction? |\n",
    "|:------------------:|:--------------------:|\n",
    "| 50 / 50 | ‚ùå No |\n",
    "| 70 / 30 | ‚ö†Ô∏è Depends on the case |\n",
    "| 80 / 20 or more extreme | ‚úÖ Probably yes |\n",
    "\n",
    "In medical classification, a high imbalance can be critical since **false negatives** (failing to detect real disease) have more severe consequences than false positives.\n",
    "\n",
    "---\n",
    "\n",
    "üìò **What will we do?**\n",
    "\n",
    "1. Visualize the distribution of `HeartDisease` using a bar chart.  \n",
    "2. Display the **percentage of each class** (`0` and `1`).  \n",
    "3. Make decisions regarding:\n",
    "   - Whether balancing techniques are necessary.  \n",
    "   - Which metrics to prioritize during evaluation.  \n",
    "   - How to configure cross-validation.\n",
    "\n",
    "This analysis ensures that subsequent modeling will be **balanced, fair, and clinically meaningful**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397ffd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute and relative count of the target variable\n",
    "target_counts = df[\"HeartDisease\"].value_counts()\n",
    "target_percent = df[\"HeartDisease\"].value_counts(normalize=True) * 100\n",
    "\n",
    "# Visualization of the target variable distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(\n",
    "    data=df,\n",
    "    x=\"HeartDisease\",\n",
    "    palette=\"Set2\"\n",
    ")\n",
    "plt.title(\"Distribution of HeartDisease (Target Variable)\", fontsize=12)\n",
    "plt.xlabel(\"HeartDisease (0 = No Disease, 1 = With Disease)\")\n",
    "plt.ylabel(\"Number of Cases\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display absolute and relative class counts\n",
    "print(\"Class Counts:\")\n",
    "print(target_counts)\n",
    "print(\"\\nClass Percentages (%):\")\n",
    "print(target_percent.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d491e360",
   "metadata": {},
   "source": [
    "**Results Analysis**\n",
    "\n",
    "The target variable distribution is **fairly balanced**.  \n",
    "Although not exactly 50/50, the difference (~10%) is not enough to be considered a **class imbalance problem**.\n",
    "\n",
    "Therefore:\n",
    "- It is not necessary to apply rebalancing techniques such as **SMOTE**, **undersampling**, or **class weights**.  \n",
    "- The model can be trained without additional class correction.  \n",
    "- Standard evaluation metrics can be used, including:\n",
    "\n",
    "  - **Accuracy**  \n",
    "  - **Precision**  \n",
    "  - **Recall**  \n",
    "  - **F1-score**  \n",
    "  - **AUC** (*Area Under the ROC Curve*, especially useful for binary classification).\n",
    "\n",
    "---\n",
    "\n",
    "### General Conclusions from the EDA\n",
    "\n",
    "Throughout the exploratory data analysis, the dataset has been examined from multiple perspectives.  \n",
    "Below is a summary of the main findings by phase:\n",
    "\n",
    "| **Phase** | **Main Findings** |\n",
    "|:-----------|:------------------|\n",
    "| **Structural Review** | Complete dataset with no missing values. Some variables contain invalid values (e.g., `0` in RestingBP or Cholesterol). |\n",
    "| **Numerical Variables** | All show statistically significant differences with `HeartDisease`. Outliers and skewness were identified and will need treatment. |\n",
    "| **Categorical Variables** | All show statistically significant association with the target variable. |\n",
    "| **Target Variable** | Balanced distribution (‚âà45% / 55%), no need for resampling or balancing techniques. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b67805e",
   "metadata": {},
   "source": [
    "## üß™ Phase 3 ‚Äî Feature Engineering and Encoding\n",
    "\n",
    "üéØ **Objective**\n",
    "\n",
    "**Feature engineering** is one of the most critical stages in any *Machine Learning* project.  \n",
    "Its purpose is to **transform raw data into a clean, consistent, and representative format**, so that algorithms can efficiently and reliably learn patterns.\n",
    "\n",
    "This step is not just technical but strategic ‚Äî it determines the real quality of the final model.\n",
    "\n",
    "---\n",
    "\n",
    "üß© **What does this phase include?**\n",
    "\n",
    "During feature engineering, the following tasks are performed:\n",
    "\n",
    "- **Correction of structural errors or impossible values.**  \n",
    "- **Encoding of categorical variables**, adapting them to numerical format:  \n",
    "  - Binary ‚Üí (0/1).  \n",
    "  - Nominal ‚Üí *One-Hot Encoding*.  \n",
    "  - Ordinal ‚Üí encoding that preserves semantic order.  \n",
    "- **Transformation of skewed variables** to reduce bias or long tails.  \n",
    "- **Scaling of variables**, when required by the model.  \n",
    "- **Separation of predictor variables (`X`) and the target variable (`y`).**  \n",
    "- **Splitting the dataset into training and test sets** to ensure fair evaluation.\n",
    "\n",
    "The result will be a **clean, numerical, and fully model-ready dataset**.\n",
    "\n",
    "---\n",
    "\n",
    "üìò **Subphases of Feature Engineering**\n",
    "\n",
    "1. **Cleaning invalid values**  \n",
    "   (For example: impossible values such as 0 in `RestingBP` or `Cholesterol`.)\n",
    "\n",
    "2. **Encoding categorical variables**  \n",
    "   - Binary  \n",
    "   - Nominal (*One-Hot*)  \n",
    "   - Ordinal (preserving semantic order)\n",
    "\n",
    "3. **Transformation of distributions**  \n",
    "   (Apply *log*, *sqrt*, or robust methods if strong skewness is present.)\n",
    "\n",
    "4. **Scaling of variables**  \n",
    "   (Normalization or standardization when required for magnitude-sensitive models.)\n",
    "\n",
    "5. **Data separation and partitioning**  \n",
    "   (Split the dataset into `X_train`, `X_test`, `y_train`, and `y_test`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f360e01d",
   "metadata": {},
   "source": [
    "### ‚úÖ Step 1 ‚Äî Cleaning Invalid Values\n",
    "\n",
    "üß† **What does ‚Äúinvalid‚Äù mean?**\n",
    "\n",
    "These are not missing (`NaN`) values, but **values that lack clinical or logical meaning**, even though they exist in the dataset.\n",
    "\n",
    "In this case:\n",
    "\n",
    "| Variable | Description | Invalid Value | Reason |\n",
    "|:----------|:-------------|:--------------:|:--------|\n",
    "| `RestingBP` | Resting blood pressure | 0 | Physiologically impossible |\n",
    "| `Cholesterol` | Serum cholesterol | 0 | Medically implausible |\n",
    "| `Oldpeak` | ST depression | < 0 | Medically impossible |\n",
    "\n",
    "Completely removing records with a single invalid field is not always recommended, as it can lead to **unnecessary data loss**.  \n",
    "Therefore, we will apply **strategic imputation**, replacing invalid values with a representative measure (such as the **median**), preserving the overall distribution integrity.\n",
    "\n",
    "---\n",
    "\n",
    "üìä With this initial cleaning, we ensure that numerical variables are **free from clinical inconsistencies**, preparing them for the next phase of encoding and transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb351f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original DataFrame to preserve unmodified data\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Identify impossible values in clinical variables\n",
    "invalid_bp = (df_clean[\"RestingBP\"] == 0).sum()\n",
    "invalid_chol = (df_clean[\"Cholesterol\"] == 0).sum()\n",
    "invalid_oldpeak = (df_clean[\"Oldpeak\"] < 0).sum()\n",
    "\n",
    "print(f\"Invalid values in RestingBP = 0: {invalid_bp}\")\n",
    "print(f\"Invalid values in Cholesterol = 0: {invalid_chol}\")\n",
    "print(f\"Invalid values in Oldpeak < 0: {invalid_oldpeak}\")\n",
    "\n",
    "# Calculate medians excluding invalid values (0)\n",
    "bp_median = df_clean.loc[df_clean[\"RestingBP\"] > 0, \"RestingBP\"].median()\n",
    "chol_median = df_clean.loc[df_clean[\"Cholesterol\"] > 0, \"Cholesterol\"].median()\n",
    "\n",
    "# Impute invalid values with the corresponding median\n",
    "df_clean.loc[df_clean[\"RestingBP\"] == 0, \"RestingBP\"] = bp_median\n",
    "df_clean.loc[df_clean[\"Cholesterol\"] == 0, \"Cholesterol\"] = chol_median\n",
    "df_clean.loc[df_clean[\"Oldpeak\"] < 0, \"Oldpeak\"] = 0\n",
    "\n",
    "# Confirm replacement and display the medians used\n",
    "print(\"\\nReplacement completed:\")\n",
    "print(f\"  - Median used for RestingBP: {bp_median}\")\n",
    "print(f\"  - Median used for Cholesterol: {chol_median}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a379888f",
   "metadata": {},
   "source": [
    "### üî° Step 2 ‚Äî Encoding Categorical Variables\n",
    "\n",
    "üß† **Why is encoding necessary?**\n",
    "\n",
    "*Machine Learning* algorithms **cannot process text or categorical labels** directly.  \n",
    "They require all variables to be represented in **numeric format**, while still preserving the semantic information they convey.\n",
    "\n",
    "For example, models cannot correctly interpret values like `'M'`, `'ATA'`, or `'Y'` unless they are first transformed into numbers.\n",
    "\n",
    "However, **not all categorical variables are encoded in the same way** ‚Äî the proper method depends on the type of variable and the meaning of its categories.\n",
    "\n",
    "---\n",
    "\n",
    "üìä **Types of Variables and Recommended Encoding**\n",
    "\n",
    "| Variable Type | Example | Recommended Encoding |\n",
    "|:----------------|:---------|:----------------------|\n",
    "| **Binary** | `Sex`, `ExerciseAngina` | Direct 0/1 encoding (`map()` or `Label Encoding`) |\n",
    "| **Nominal** (no inherent order) | `ChestPainType`, `RestingECG` | *One-Hot Encoding* (creates dummy columns) |\n",
    "| **Ordinal** (semantic order) | `ST_Slope` | Ordinal encoding (`Down` = 0, `Flat` = 1, `Up` = 2) |\n",
    "\n",
    "---\n",
    "\n",
    "üßæ **How will we do it?**\n",
    "\n",
    "1. **Direct binary encoding**  \n",
    "   - Transform binary variables (`Sex`, `ExerciseAngina`) using `map()`:\n",
    "     - `Sex`: `'M' ‚Üí 1`, `'F' ‚Üí 0`  \n",
    "     - `ExerciseAngina`: `'Y' ‚Üí 1`, `'N' ‚Üí 0`\n",
    "\n",
    "2. **Ordinal encoding**  \n",
    "   - The variable `ST_Slope` has a clinically meaningful progression:\n",
    "     - `Down` = 0 (worst)  \n",
    "     - `Flat` = 1 (intermediate)  \n",
    "     - `Up` = 2 (best)  \n",
    "   - It will be represented with this numeric scale to preserve the relationship.\n",
    "\n",
    "3. **Nominal encoding (One-Hot Encoding)**  \n",
    "   - Variables without natural order (`ChestPainType`, `RestingECG`) will be encoded using *One-Hot Encoding*, generating a binary column for each category.\n",
    "\n",
    "---\n",
    "\n",
    "üìò **Expected Result:**  \n",
    "After this process, we will obtain a fully numeric dataset, where each category is properly represented according to its nature.  \n",
    "This allows *Machine Learning* algorithms to interpret the information correctly and without artificial bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dc6dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on a clean copy of the dataset\n",
    "# This process transforms all categorical variables into numeric format\n",
    "# while respecting their type (binary, nominal, or ordinal).\n",
    "\n",
    "# 1. Binary variable encoding (Sex, ExerciseAngina)\n",
    "# Convert text to numeric values while preserving interpretation.\n",
    "df_clean[\"Sex\"] = df_clean[\"Sex\"].map({\"M\": 1, \"F\": 0})\n",
    "df_clean[\"ExerciseAngina\"] = df_clean[\"ExerciseAngina\"].map({\"Y\": 1, \"N\": 0})\n",
    "\n",
    "# 2. Ordinal encoding (ST_Slope)\n",
    "# This variable has a clinically meaningful order:\n",
    "# Down < Flat < Up  ‚Üí  from worse to better cardiac response.\n",
    "slope_mapping = {\"Down\": 0, \"Flat\": 1, \"Up\": 2}\n",
    "df_clean[\"ST_Slope\"] = df_clean[\"ST_Slope\"].map(slope_mapping)\n",
    "\n",
    "# 3. One-Hot Encoding for nominal variables (ChestPainType, RestingECG)\n",
    "# Create dummy columns while avoiding multicollinearity (drop_first=True).\n",
    "df_clean = pd.get_dummies(\n",
    "    df_clean,\n",
    "    columns=[\"ChestPainType\", \"RestingECG\"],\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# Display summary of results\n",
    "print(\"Final dimensions of the encoded dataset:\", df_clean.shape)\n",
    "print(\"\\nResulting columns:\")\n",
    "print(df_clean.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abed8d28",
   "metadata": {},
   "source": [
    "### ‚úÖ Step 3 ‚Äî Transformation of Distributions\n",
    "\n",
    "In *Machine Learning* projects, not all numerical variables have a distribution suitable for modeling.  \n",
    "Some may be **highly skewed**, have **extreme values**, or **imbalanced scales**, which can negatively affect algorithm performance.\n",
    "\n",
    "---\n",
    "\n",
    "üéØ **Why transform numerical variables?**\n",
    "\n",
    "The goal of transformations is not to ‚Äúnormalize by habit,‚Äù but to **improve model learning stability**.\n",
    "\n",
    "Common reasons to transform data:\n",
    "- **Outliers:** extreme values dominate model behavior.  \n",
    "- **Strong skewness:** data concentrated in a narrow range.  \n",
    "- **Very different scales among variables**, which affects convergence in distance- or gradient-based algorithms.\n",
    "\n",
    "Models most sensitive to these issues:\n",
    "- **Linear models** ‚Üí e.g., *Logistic Regression*.  \n",
    "- **Distance-based models** ‚Üí e.g., *k-NN*, *SVM*, *clustering*.  \n",
    "- **Neural networks**, where extreme values can distort gradient propagation.\n",
    "\n",
    "---\n",
    "\n",
    "üéØ **Objective of transformation**\n",
    "\n",
    "Transform only those variables that **truly need it**, in order to:\n",
    "- Smooth skewed distributions.  \n",
    "- Reduce the effect of outliers.  \n",
    "- Improve numerical stability during training.\n",
    "\n",
    "---\n",
    "\n",
    "üîç **Candidate variables for transformation in this dataset**\n",
    "\n",
    "| Variable | Identified Issue | Recommended Action |\n",
    "|:----------|:-----------------|:-------------------|\n",
    "| **Oldpeak** | Highly right-skewed distribution. | Apply `log1p()` |\n",
    "| **Cholesterol** | High positive outliers. | Apply `log1p()` directly |\n",
    "| **RestingBP** | Some outliers but acceptable distribution. | Only scale later |\n",
    "| **MaxHR** | Slight asymmetry, clinically coherent. | No transformation (optional scaling) |\n",
    "\n",
    "---\n",
    "\n",
    "üìä **Expected Result:**  \n",
    "A set of numerical variables that are more stable, with smoothed distributions, ready for scaling and use in predictive modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2674fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply logarithmic transformations\n",
    "# log1p(x) = log(1 + x), which safely handles zero values without mathematical errors.\n",
    "df_clean[\"Oldpeak_log\"] = np.log1p(df_clean[\"Oldpeak\"])          # Reduces skewness and outliers\n",
    "df_clean[\"Cholesterol_log\"] = np.log1p(df_clean[\"Cholesterol\"])  # Smooths cholesterol distribution\n",
    "\n",
    "# Verify the result\n",
    "# Compare original and transformed distributions using descriptive statistics.\n",
    "print(\"\\nStatistical summary after logarithmic transformation:\")\n",
    "print(df_clean[[\"Oldpeak\", \"Oldpeak_log\", \"Cholesterol\", \"Cholesterol_log\"]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the applied transformation on numerical variables\n",
    "# Compare the original and transformed shapes to verify skewness reduction.\n",
    "\n",
    "# --- Oldpeak ---\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(df_clean[\"Oldpeak\"], kde=True, color=\"skyblue\")\n",
    "plt.title(\"Oldpeak Distribution (Original)\")\n",
    "plt.xlabel(\"Oldpeak\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(df_clean[\"Oldpeak_log\"], kde=True, color=\"lightcoral\")\n",
    "plt.title(\"Oldpeak Distribution (Transformed)\")\n",
    "plt.xlabel(\"Oldpeak_log\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Cholesterol ---\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(df_clean[\"Cholesterol\"], kde=True, color=\"skyblue\")\n",
    "plt.title(\"Cholesterol Distribution (Original)\")\n",
    "plt.xlabel(\"Cholesterol\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(df_clean[\"Cholesterol_log\"], kde=True, color=\"lightcoral\")\n",
    "plt.title(\"Cholesterol Distribution (Transformed)\")\n",
    "plt.xlabel(\"Cholesterol_log\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa524319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the original columns already transformed to avoid duplicated information.\n",
    "# Keep only the logarithmic versions (Oldpeak_log, Cholesterol_log).\n",
    "df_clean.drop(columns=[\"Oldpeak\", \"Cholesterol\"], inplace=True)\n",
    "\n",
    "# Confirm changes\n",
    "print(\"Removed columns: ['Oldpeak', 'Cholesterol']\")\n",
    "print(\"Current columns in the dataset:\")\n",
    "print(df_clean.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c0bc89",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Step 4 ‚Äî Feature Scaling (Normalization or Standardization)\n",
    "\n",
    "üéØ **Why scale?**\n",
    "\n",
    "*Machine Learning* algorithms don‚Äôt understand human magnitudes ‚Äî they only work with numbers.  \n",
    "Therefore, if one variable has a much larger range (e.g., `Age` between 30 and 80) and another uses binary values (`0` or `1`), the model may:\n",
    "\n",
    "- **Give more weight to variables with larger values**, even if they‚Äôre not more important.  \n",
    "- **Take longer to converge**, as it must adjust parameters on very different scales.  \n",
    "- **Perform worse**, especially for models that depend on distances or gradients.\n",
    "\n",
    "---\n",
    "\n",
    "üß† **Which models require scaling?**\n",
    "\n",
    "| Model Type | Requires Scaling? |\n",
    "|:------------|:-----------------:|\n",
    "| **K-Nearest Neighbors (KNN)** | ‚úÖ Yes |\n",
    "| **Support Vector Machines (SVM)** | ‚úÖ Yes |\n",
    "| **Logistic Regression** | ‚úÖ Yes |\n",
    "| **Neural Networks** | ‚úÖ Yes |\n",
    "| **Decision Trees, Random Forest, XGBoost** | ‚ùå No |\n",
    "\n",
    "---\n",
    "\n",
    "üßÆ **Common Scaling Techniques**\n",
    "\n",
    "| Method | What it does | When to use |\n",
    "|:---------|:--------------|:-------------|\n",
    "| **StandardScaler** | Centers data (mean = 0, standard deviation = 1). | When variables are approximately normally distributed. |\n",
    "| **MinMaxScaler** | Rescales data between `[0, 1]`. | When variables are not normally distributed or proportions need to be preserved. |\n",
    "| **RobustScaler** | Scales using the **median** and **interquartile range (IQR)**. | Ideal when outliers are present, as it is more resistant to extreme values. |\n",
    "\n",
    "---\n",
    "\n",
    "üìò **In our case: which technique will we apply?**\n",
    "\n",
    "- We already applied logarithmic transformations to skewed variables (`Oldpeak_log`, `Cholesterol_log`), making them more stable.  \n",
    "- We plan to use models such as **Logistic Regression**, which **require scaling**.  \n",
    "- Some outliers still exist, so we‚Äôll use **`RobustScaler`**, which balances normalization and robustness against outliers.\n",
    "\n",
    "---\n",
    "\n",
    "üìã **Variables to Scale**\n",
    "\n",
    "| Type | Variables | Action |\n",
    "|:------|:-----------|:--------|\n",
    "| **Continuous Numerical** | `Age`, `RestingBP`, `MaxHR`, `Oldpeak_log`, `Cholesterol_log` | ‚úÖ Scale with `RobustScaler` |\n",
    "| **Binary** | `Sex`, `ExerciseAngina`, `FastingBS` | ‚ùå Do not scale |\n",
    "| **One-Hot / Ordinal** | `ST_Slope`, dummy variables (`ChestPainType_*`, `RestingECG_*`) | ‚ùå Do not scale |\n",
    "\n",
    "---\n",
    "\n",
    "üìå **Summary**\n",
    "\n",
    "We will apply **scaling only to continuous numerical variables**, leaving binary and encoded categorical variables unchanged.  \n",
    "This ensures that scale-sensitive models (like SVM, Logistic Regression, or Neural Networks) can learn properly without distorting categorical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f4656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select continuous numerical variables that require scaling\n",
    "numeric_features = [\"Age\", \"RestingBP\", \"MaxHR\", \"Oldpeak_log\", \"Cholesterol_log\"]\n",
    "\n",
    "# Initialize the robust scaler (less sensitive to outliers)\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Apply scaling to the selected variables\n",
    "df_clean[numeric_features] = scaler.fit_transform(df_clean[numeric_features])\n",
    "\n",
    "# Verify the result: medians should be close to 0 and the interquartile range around 1\n",
    "print(\"Statistical summary of scaled variables:\\n\")\n",
    "print(df_clean[numeric_features].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f9856",
   "metadata": {},
   "source": [
    "### üß© Step 5 ‚Äî Data Separation and Splitting\n",
    "\n",
    "This is the **final step in the data preparation phase**, where we make everything ready for supervised modeling.\n",
    "\n",
    "---\n",
    "\n",
    "üéØ **Why separate and split?**\n",
    "\n",
    "1. **Separation between predictor and target variables**  \n",
    "- `X` ‚Üí contains all **predictor variables** (features).  \n",
    "- `y` ‚Üí contains only the **target variable**, in this case `HeartDisease`.  \n",
    "\n",
    "This separation ensures that the learning algorithms know which variable to predict without accidentally including it during training.\n",
    "\n",
    "---\n",
    "\n",
    "2. **Dataset splitting (Train/Test Split)**  \n",
    "\n",
    "Once `X` and `y` are separated, the dataset is divided into two subsets:  \n",
    "- **Training set (train):** used to fit the model parameters.  \n",
    "- **Test set (test):** used to evaluate model performance on unseen data.\n",
    "\n",
    "This prevents **overfitting**, ensuring that the model learns general patterns rather than memorizing the training data.\n",
    "\n",
    "---\n",
    "\n",
    "‚öñÔ∏è **Class stratification**\n",
    "\n",
    "Since the target variable `HeartDisease` has a slightly unbalanced distribution (~55% with disease, ~45% without), we apply **stratification** during the split.  \n",
    "\n",
    "This guarantees that **the class proportions remain the same** in both the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bb27c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate predictor variables (X) and target variable (y)\n",
    "X = df_clean.drop(columns=[\"HeartDisease\"])\n",
    "y = df_clean[\"HeartDisease\"]\n",
    "\n",
    "# Split the dataset into training and test sets with stratification\n",
    "# This maintains the class proportion (~55% vs ~45%) in both subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,        # 80% training / 20% testing\n",
    "    stratify=y,           # preserve class proportions\n",
    "    random_state=42       # ensure reproducibility\n",
    ")\n",
    "\n",
    "# Verify sizes and class distributions\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "\n",
    "print(\"\\nClass distribution in y_train (%):\")\n",
    "print(y_train.value_counts(normalize=True).round(3) * 100)\n",
    "\n",
    "print(\"\\nClass distribution in y_test (%):\")\n",
    "print(y_test.value_counts(normalize=True).round(3) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4d441e",
   "metadata": {},
   "source": [
    "## ‚úÖ Phase 4 ‚Äî Model Training and Comparison  \n",
    "### üß™ Benchmark Model: Logistic Regression\n",
    "\n",
    "---\n",
    "\n",
    "üéØ **Objective of this step**\n",
    "\n",
    "Before testing more complex models, we will train a **baseline or benchmark model** to establish a minimum performance reference.  \n",
    "The goal is not to maximize metrics yet, but to **evaluate the predictive potential of the data** and verify that the preprocessing pipeline works correctly.\n",
    "\n",
    "This step allows us to:\n",
    "\n",
    "- Check whether the data contains **relevant predictive information**.  \n",
    "- Establish a **baseline performance** to compare against other models (trees, SVM, neural networks, etc.).  \n",
    "- Detect early potential issues such as:\n",
    "  - **Overfitting** (model fits too closely to training data).  \n",
    "  - **Severe class imbalance.**  \n",
    "  - **Weak or poorly encoded relationships** between features and the target variable.\n",
    "\n",
    "---\n",
    "\n",
    "üß† **Why start with Logistic Regression?**\n",
    "\n",
    "| Key Advantage | Relevance for this Project |\n",
    "|:----------------|:---------------------------|\n",
    "| **Very fast to train** | ‚úî Dataset of moderate size |\n",
    "| **Highly interpretable** | ‚úî Allows analysis of variable coefficients |\n",
    "| **Efficient for linear relationships** | ‚úî We have already performed transformations and scaling |\n",
    "| **Serves as an initial benchmark** | ‚úî Solid foundation for comparing other models |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d097d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the baseline model: Logistic Regression\n",
    "# Used as an initial benchmark for its interpretability and speed\n",
    "model_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model_lr.predict(X_test)\n",
    "y_prob = model_lr.predict_proba(X_test)[:, 1]  # Probability of positive class (HeartDisease = 1)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Compute AUC (Area Under the ROC Curve)\n",
    "auc_value = roc_auc_score(y_test, y_prob)\n",
    "print(f\"\\nAUC: {auc_value:.4f}\")\n",
    "\n",
    "# Visualize ROC curve\n",
    "RocCurveDisplay.from_estimator(model_lr, X_test, y_test)\n",
    "plt.title(\"ROC Curve - Logistic Regression (Benchmark)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9799cf5",
   "metadata": {},
   "source": [
    "### Interpretation of the Benchmark Model ‚Äî Logistic Regression\n",
    "\n",
    "After training the baseline model, we analyze its metrics and overall behavior to evaluate its usefulness as a starting point for the project.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Metrics from the `classification_report`\n",
    "\n",
    "| Class | Precision | Recall | F1-Score | Support |\n",
    "|:------|:-----------:|:---------:|:---------:|:---------:|\n",
    "| **0 (No disease)** | 0.88 | 0.82 | 0.85 | 82 |\n",
    "| **1 (With disease)** | 0.86 | 0.91 | 0.89 | 102 |\n",
    "| **‚û° Overall F1-score** | **0.87** | | | |\n",
    "\n",
    "**Interpretation:**\n",
    "- **Precision:** When the model predicts *heart disease*, it is correct **86%** of the time.  \n",
    "- **Recall:** It correctly identifies **91%** of actual disease cases.  \n",
    "  ‚Üí This is **excellent**, as the model is highly sensitive to the positive class.  \n",
    "- **Balance:** The high F1-score in both classes indicates that the model is **not biased**, despite the slight imbalance (~55% / 45%).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Confusion Matrix\n",
    "\n",
    "\\[\n",
    "\\begin{bmatrix}\n",
    "67 & 15 \\\\\n",
    "9 & 93\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "- **False negatives (9):** Cases with disease that the model **failed to detect**.  \n",
    "  ‚Üí In medical contexts, these are the most serious errors, but the number is low.  \n",
    "- **False positives (15):** Healthy cases that were classified as diseased.  \n",
    "  ‚Üí Less critical clinically; they can be verified with additional testing.\n",
    "\n",
    "üß† **Conclusion:**  \n",
    "The model tends to **prioritize disease detection (high Recall)** ‚Äî desirable behavior in a clinical setting.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. ROC Curve and AUC\n",
    "\n",
    "- **AUC = 0.90 ‚Üí Excellent discrimination.**  \n",
    "- The **ROC curve** approaches the upper-left corner, showing a **high ability to distinguish** between healthy and diseased patients.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Benchmark Conclusion\n",
    "\n",
    "| Evaluated Aspect | Result |\n",
    "|:------------------|:---------|\n",
    "| **Good starting point?** | ‚úî Yes |\n",
    "| **Visible issues?** | ‚ùå None |\n",
    "| **Apparent overfitting?** | ‚ùå Not evident |\n",
    "| **Worth optimizing further?** | ‚úî Absolutely |\n",
    "\n",
    "The baseline model already achieves:\n",
    "- **Overall F1-score ‚âà 0.87**  \n",
    "- **AUC ‚âà 0.90**\n",
    "\n",
    "This confirms that the dataset has **strong predictive potential** and that preprocessing was effective.  \n",
    "Logistic Regression provides a solid reference point for future improvements.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Next Steps\n",
    "\n",
    "1. **üîÑ Cross-Validation (K-Fold):**  \n",
    "   - Validate the stability of performance.  \n",
    "   - Obtain averaged metrics across multiple data splits.\n",
    "\n",
    "2. **ü§ñ Model Comparison:**  \n",
    "   - Train and compare additional classifiers:  \n",
    "     - Tree-based ‚Üí `RandomForest`, `XGBoost`, `GradientBoosting`  \n",
    "     - Non-linear ‚Üí `KNN`, `SVM`  \n",
    "     - Simple ‚Üí `Naive Bayes`\n",
    "\n",
    "---\n",
    "\n",
    "üìà **Final Takeaway:**  \n",
    "The logistic regression benchmark demonstrates an excellent balance between precision, sensitivity, and generalization.  \n",
    "Next, we‚Äôll move to **cross-validation and model optimization** to further improve predictive performance while maintaining interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd4fdf",
   "metadata": {},
   "source": [
    "### üå≥ Model 2 ‚Äî Decision Tree\n",
    "\n",
    "---\n",
    "\n",
    "üéØ **Objective**\n",
    "\n",
    "In this step, we will test a **non-linear and highly interpretable** model: the **Decision Tree**.  \n",
    "The goal is to **compare its performance** with the linear benchmark (Logistic Regression) and assess whether it can:\n",
    "\n",
    "- Capture **complex interactions** between variables.  \n",
    "- Detect **non-linear patterns** that a linear model cannot represent.  \n",
    "- Maintain the **interpretability** of the decision process.\n",
    "\n",
    "---\n",
    "\n",
    "üß† **Advantages of Decision Trees**\n",
    "\n",
    "| Advantage | Description |\n",
    "|:-----------|:-------------|\n",
    "| **Interpretability** | They can be easily visualized and explained (each node represents a logical rule). |\n",
    "| **Flexibility** | Handle both **numerical and categorical** variables without prior transformation. |\n",
    "| **No need for scaling** | Variable magnitude does not affect performance. |\n",
    "| **Capture non-linearities** | Detect complex relationships between predictors and the target variable. |\n",
    "| **Resistant to outliers** | Splits are based on thresholds rather than averages. |\n",
    "\n",
    "---\n",
    "\n",
    "üìò **Disadvantages (to consider)**\n",
    "\n",
    "| Limitation | Impact |\n",
    "|:-------------|:----------|\n",
    "| **Tendency to overfit (overfitting)** | May learn overly specific rules if not properly regularized with hyperparameters. |\n",
    "| **High variance** | Small data changes can produce very different trees. |\n",
    "| **Moderate standalone performance** | Individually, they often perform worse than ensemble models like Random Forest or Gradient Boosting. |\n",
    "\n",
    "---\n",
    "\n",
    "üß© **In summary**\n",
    "\n",
    "The Decision Tree is an excellent model for this stage because:\n",
    "\n",
    "- It is **interpretable**, ideal for medical contexts.  \n",
    "- It allows **exploration of non-linearities** and interactions between features.  \n",
    "- It serves as a **conceptual foundation** for more powerful ensemble models (Random Forest, Gradient Boosting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0464e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation of a Decision Tree with cross-validation\n",
    "# StratifiedKFold is used to maintain class proportions in each split\n",
    "\n",
    "# Initialize the model\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Selected evaluation metrics\n",
    "scoring = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]\n",
    "\n",
    "# Separate predictor and target variables\n",
    "X = df_clean.drop(columns=\"HeartDisease\")\n",
    "y = df_clean[\"HeartDisease\"]\n",
    "\n",
    "# Perform cross-validation\n",
    "tree_results = cross_validate(\n",
    "    estimator=tree_model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "# Convert results to DataFrame for a clear summary\n",
    "tree_df = pd.DataFrame(tree_results)[\n",
    "    [\"test_accuracy\", \"test_precision\", \"test_recall\", \"test_f1\", \"test_roc_auc\"]\n",
    "]\n",
    "\n",
    "print(\"Decision Tree Results (Cross-Validation):\")\n",
    "print(tree_df.round(4))\n",
    "\n",
    "# Calculate average metrics\n",
    "print(\"\\nAverage metrics (5-fold CV):\")\n",
    "print(tree_df.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86007083",
   "metadata": {},
   "source": [
    "üå≥ **Decision Tree ‚Äî Evaluation and Comparison**\n",
    "\n",
    "---\n",
    "\n",
    "üìä **Average Metrics (Cross-Validation)**\n",
    "\n",
    "| Metric | Decision Tree | Logistic Regression | Difference |\n",
    "|:--------|:---------------:|:------------------:|:------------:|\n",
    "| **Accuracy** | 0.772 | 0.848 | üîª ‚àí0.076 |\n",
    "| **Precision** | 0.799 | 0.853 | üîª ‚àí0.054 |\n",
    "| **Recall** | 0.787 | 0.878 | üîª ‚àí0.091 |\n",
    "| **F1-Score** | 0.793 | 0.864 | üîª ‚àí0.071 |\n",
    "| **ROC AUC** | 0.771 | 0.913 | üîª ‚àí0.142 |\n",
    "\n",
    "---\n",
    "\n",
    "üîç **Results Interpretation**\n",
    "\n",
    "The **simple Decision Tree** shows **lower performance** than Logistic Regression across all main metrics.\n",
    "\n",
    "- **Recall (78.7%)** and **AUC (77.1%)** are the most affected metrics.  \n",
    "  ‚Üí This suggests that the tree has a **weaker ability to identify true positive cases** and **discriminate between classes**.  \n",
    "- The **variation between folds** (accuracy ranging from 0.71 to 0.82) indicates **lower stability** and **greater dependence on training data**.\n",
    "\n",
    "---\n",
    "\n",
    "‚ö†Ô∏è **Possible Causes**\n",
    "\n",
    "1. **Overfitting:**  \n",
    "   By default, trees grow until they perfectly classify the training data, reducing their generalization ability.\n",
    "\n",
    "2. **High variance:**  \n",
    "   Small changes in data can completely alter the tree‚Äôs structure.\n",
    "\n",
    "3. **Lack of regularization:**  \n",
    "   Depth (`max_depth`) and minimum samples per node (`min_samples_split`) were not restricted, allowing overly specific decision rules.\n",
    "\n",
    "4. **Dataset size:**  \n",
    "   With fewer than a thousand records, trees tend to overfragment data, leading to reduced robustness.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ **Overall Conclusion**\n",
    "\n",
    "| Aspect | Decision Tree |\n",
    "|:---------|:------------------|\n",
    "| **Improves over benchmark?** | ‚ùå No |\n",
    "| **Interesting result?** | ‚úî Yes, for interpretability |\n",
    "| **Problems detected?** | ‚ö†Ô∏è Overfitting and high variance |\n",
    "| **Future usefulness?** | üß± Foundation for ensemble models (Random Forest, Gradient Boosting) |\n",
    "\n",
    "---\n",
    "\n",
    "üìò **Summary:**\n",
    "The pure Decision Tree **does not outperform the baseline model**, but it serves as a **conceptual and structural foundation** for more powerful and stable ensemble methods such as **Random Forest** and **Gradient Boosting**, which combine multiple trees to improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e9b2b4",
   "metadata": {},
   "source": [
    "### üå≤ Model 3 ‚Äî Random Forest\n",
    "\n",
    "---\n",
    "\n",
    "üéØ **What is it and why use it?**\n",
    "\n",
    "**Random Forest** is an *ensemble* model based on **multiple Decision Trees**.  \n",
    "Each tree is trained on:\n",
    "\n",
    "1. **Random subsets of the data (bagging)**  \n",
    "2. **Random subsets of features** at each node  \n",
    "\n",
    "This introduces **diversity** among the trees, and by combining their predictions (via majority voting for classification), the model becomes more stable and achieves better generalization than a single tree.\n",
    "\n",
    "---\n",
    "\n",
    "üß† **Intuition behind the model**\n",
    "\n",
    "- A single tree can easily **overfit** (learn training data too specifically).  \n",
    "- If you train **many trees on different subsets of data**, each will make different mistakes.  \n",
    "- By **averaging** their results, those errors tend to **cancel out**, reducing the overall model variance.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ **Advantages of Random Forest**\n",
    "\n",
    "| Advantage | Explanation |\n",
    "|:-----------|:-------------|\n",
    "| **‚úÖ Reduces overfitting** | Averaging multiple trees smooths out individual errors. |\n",
    "| **‚úÖ Excellent general performance** | Often a strong *baseline* for tabular classification problems. |\n",
    "| **‚úÖ Relative interpretability** | Provides **feature importance** scores, helping to understand influential factors. |\n",
    "| **‚úÖ Handles heterogeneous data** | Works well with numerical, categorical, and mixed data without the need for scaling. |\n",
    "\n",
    "---\n",
    "\n",
    "‚ö†Ô∏è **Considerations**\n",
    "\n",
    "| Limitation | Explanation |\n",
    "|:-------------|:-------------|\n",
    "| **Less interpretable than a single tree** | While more robust, its structure is less transparent. |\n",
    "| **Higher computational cost** | Training hundreds of trees requires more time and memory. |\n",
    "| **Harder to visualize** | Cannot be easily represented graphically like an individual tree. |\n",
    "\n",
    "---\n",
    "\n",
    "üìò **Why it‚Äôs ideal for our case**\n",
    "\n",
    "- The dataset is already clean and well-encoded.  \n",
    "- It includes both numerical and categorical variables.  \n",
    "- The goal is to **improve recall and AUC** without losing interpretability.  \n",
    "\n",
    "Therefore, **Random Forest** is a natural next step after the simple tree ‚Äî it keeps the previous model‚Äôs strengths while **reducing variance** and **improving stability and accuracy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a2b931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation of a Random Forest model using cross-validation\n",
    "# This model combines multiple decision trees to improve generalization and reduce overfitting\n",
    "\n",
    "# Initialize the model using all available CPU cores\n",
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Define stratified cross-validation (preserves class proportions)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Selected evaluation metrics\n",
    "scoring = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]\n",
    "\n",
    "# Separate predictor and target variables\n",
    "X = df_clean.drop(columns=\"HeartDisease\")\n",
    "y = df_clean[\"HeartDisease\"]\n",
    "\n",
    "# Perform cross-validation\n",
    "rf_results = cross_validate(\n",
    "    estimator=rf_model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "# Convert results to a DataFrame for clear analysis\n",
    "rf_df = pd.DataFrame(rf_results)[\n",
    "    [\"test_accuracy\", \"test_precision\", \"test_recall\", \"test_f1\", \"test_roc_auc\"]\n",
    "]\n",
    "\n",
    "print(\"Random Forest Model Results (Cross-Validation):\")\n",
    "print(rf_df.round(4))\n",
    "\n",
    "# Calculate average metrics\n",
    "print(\"\\nAverage Metrics (5-fold CV):\")\n",
    "print(rf_df.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d862c09",
   "metadata": {},
   "source": [
    "üå≤ Model Evaluation ‚Äî Random Forest\n",
    "\n",
    "---\n",
    "\n",
    "üìä Average Metrics (Cross-Validation ‚Äî 5 folds)\n",
    "\n",
    "| Metric | Random Forest | Logistic Regression | Decision Tree |\n",
    "|:--------|:--------------:|:------------------:|:----------------:|\n",
    "| **Accuracy** | 0.8627 | 0.8475 | 0.7723 |\n",
    "| **Precision** | 0.8649 | 0.8526 | 0.7990 |\n",
    "| **Recall** | 0.8938 | 0.8781 | 0.7874 |\n",
    "| **F1-Score** | 0.8783 | 0.8641 | 0.7928 |\n",
    "| **ROC AUC** | 0.9229 | 0.9129 | 0.7705 |\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ Results Analysis\n",
    "\n",
    "The **Random Forest** outperforms both **Logistic Regression** and the **simple Decision Tree** across **all evaluated metrics**.\n",
    "\n",
    "- **Accuracy (86%)** ‚Üí The model correctly classifies most patients.  \n",
    "- **Recall (89%)** ‚Üí Excellent sensitivity: it detects the vast majority of heart disease cases.  \n",
    "- **Precision (86%)** ‚Üí Keeps the number of false positives low.  \n",
    "- **AUC (0.92)** ‚Üí Indicates **excellent discriminative ability** between healthy and diseased patients.  \n",
    "- **Variance between folds** ‚Üí Very low, showing **stability** and **consistency** in the results.\n",
    "\n",
    "---\n",
    "\n",
    "üß† Interpretation\n",
    "\n",
    "- The model **learns complex non-linear relationships** and **combines multiple data perspectives** thanks to the tree ensemble.  \n",
    "- The high **recall** suggests it is especially useful in clinical contexts, where **detecting a possible disease case** is preferable to missing one.  \n",
    "- Maintains a **good balance between precision and sensitivity**, with no signs of overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "üî• Conclusion\n",
    "\n",
    "| Aspect | Evaluation |\n",
    "|:----------|:------------|\n",
    "| **Overall Performance** | üöÄ Excellent |\n",
    "| **Stability** | ‚úî High |\n",
    "| **Overfitting** | ‚ùå Not evident |\n",
    "| **Explainability** | ‚úî Retains interpretability via feature importance |\n",
    "| **Position** | üèÜ Main candidate for final model |\n",
    "\n",
    "---\n",
    "\n",
    "üìà **Summary:**  \n",
    "The **Random Forest** proves to be a **robust, stable, and highly predictive model**.  \n",
    "It offers an **ideal balance between performance and interpretability**, making it an **excellent candidate for the project‚Äôs final model**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3424e29",
   "metadata": {},
   "source": [
    "### ‚ö° Model 4 ‚Äî Gradient Boosting (Scikit-learn)\n",
    "\n",
    "---\n",
    "\n",
    "üéØ What is it and why try it?\n",
    "\n",
    "**Gradient Boosting** is another tree-based *ensemble* method, similar to Random Forest, but with a **different learning philosophy**.\n",
    "\n",
    "While **Random Forest** trains many trees **independently** and averages their predictions,  \n",
    "**Gradient Boosting** trains them **sequentially**, so that **each new tree corrects the errors** made by the previous ones.\n",
    "\n",
    "This way, the model progressively learns the most difficult patterns, allowing it to achieve **higher accuracy and flexibility**.\n",
    "\n",
    "---\n",
    "\n",
    "üß† Algorithm intuition\n",
    "\n",
    "1. Starts with a simple model (for example, a small tree).  \n",
    "2. Calculates the errors (*residuals*) of the model.  \n",
    "3. Trains a new tree to predict those errors.  \n",
    "4. Combines the new tree with the previous one using a learning rate (*learning_rate*).  \n",
    "5. Repeats the process dozens or hundreds of times.\n",
    "\n",
    "The final result is a weighted combination of many weak trees that, together, form a **powerful and accurate model**.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ Advantages of Gradient Boosting\n",
    "\n",
    "| Advantage | Explanation |\n",
    "|:-----------|:-------------|\n",
    "| **‚úÖ Often outperforms Random Forest** | Learns from previous errors, achieving higher accuracy and precision. |\n",
    "| **‚úÖ Allows regularization** | Parameters like `learning_rate`, `max_depth`, and `n_estimators` control overfitting. |\n",
    "| **‚úÖ No scaling required** | Tree-based methods are independent of feature magnitude. |\n",
    "| **‚úÖ Variable interpretability** | Provides feature importance, showing which variables influence the prediction most. |\n",
    "\n",
    "---\n",
    "\n",
    "‚ö†Ô∏è Limitations\n",
    "\n",
    "| Limitation | Explanation |\n",
    "|:-------------|:-------------|\n",
    "| **Slower training** | Trees are built sequentially, not in parallel. |\n",
    "| **Higher overfitting risk** | If hyperparameters (number of trees, depth, learning rate) are not tuned properly. |\n",
    "| **Noise sensitivity** | May try to learn irrelevant patterns if the dataset is noisy. |\n",
    "\n",
    "---\n",
    "\n",
    "üìò In our case\n",
    "\n",
    "- Moderate dataset ‚Üí Fast and stable training.  \n",
    "- Well-encoded variables ‚Üí Ideal for tree-based models.  \n",
    "- Our goal is to improve **AUC and recall** compared to Random Forest while maintaining good interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c38ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation of the Gradient Boosting model using cross-validation\n",
    "# This model trains trees sequentially, each one correcting the errors of the previous one\n",
    "\n",
    "# Base model initialization\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Definition of stratified cross-validation to maintain class proportions\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluation metrics\n",
    "scoring = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]\n",
    "\n",
    "# Separation of predictor and target variables\n",
    "X = df_clean.drop(columns=\"HeartDisease\")\n",
    "y = df_clean[\"HeartDisease\"]\n",
    "\n",
    "# Execution of cross-validation\n",
    "gb_results = cross_validate(\n",
    "    estimator=gb_model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "# Conversion to DataFrame for results analysis\n",
    "gb_df = pd.DataFrame(gb_results)[\n",
    "    [\"test_accuracy\", \"test_precision\", \"test_recall\", \"test_f1\", \"test_roc_auc\"]\n",
    "]\n",
    "\n",
    "print(\"Gradient Boosting Model Results (Cross-Validation):\")\n",
    "print(gb_df.round(4))\n",
    "\n",
    "# Calculation of average metrics\n",
    "print(\"\\nAverage metrics (5-fold CV):\")\n",
    "print(gb_df.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd6db5e",
   "metadata": {},
   "source": [
    "‚ö° Model Evaluation ‚Äî Gradient Boosting (Scikit-learn)\n",
    "\n",
    "---\n",
    "\n",
    "üìä Average Metrics (Cross-Validation ‚Äî 5 folds)\n",
    "\n",
    "| Metric | Gradient Boosting | Random Forest | Difference |\n",
    "|:--------|:----------------:|:--------------:|:----------:|\n",
    "| **Accuracy** | 0.8638 | 0.8627 | üîº +0.0011 |\n",
    "| **Precision** | 0.8652 | 0.8649 | üîº +0.0003 |\n",
    "| **Recall** | 0.8958 | 0.8938 | üîº +0.0020 |\n",
    "| **F1-Score** | 0.8796 | 0.8783 | üîº +0.0013 |\n",
    "| **ROC AUC** | 0.9230 | 0.9229 | üîº +0.0001 |\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ Interpretation of Results\n",
    "\n",
    "- The **Gradient Boosting** model shows a **slight but consistent improvement** in all metrics compared to **Random Forest**.  \n",
    "- The differences are small but **remain stable across the 5 folds**, indicating good **robustness and generalization**.  \n",
    "- **Recall (89.6%)** ‚Üí Excellent ability to detect true disease cases.  \n",
    "- **AUC (0.923)** ‚Üí Confirms a **strong discriminative power** between healthy and diseased patients.  \n",
    "- The balance between **precision and sensitivity** is optimal, with no signs of overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "üß† Additional Observations\n",
    "\n",
    "- **Gradient Boosting** learns sequentially from previous model errors, refining the decision boundaries.  \n",
    "- This explains its **slight superiority in recall and F1-score**, as it captures more subtle patterns that random forests might miss.  \n",
    "- The model‚Äôs **stability** makes it a strong candidate for clinical or production deployment.\n",
    "\n",
    "---\n",
    "\n",
    "üî• Conclusion\n",
    "\n",
    "| Aspect | Evaluation |\n",
    "|:----------|:------------|\n",
    "| **Overall performance** | üöÄ Excellent |\n",
    "| **Improvement over Random Forest** | üîº Yes, though marginal |\n",
    "| **Stability (variance across folds)** | ‚úî Very high |\n",
    "| **Overfitting** | ‚ùå Not evident |\n",
    "| **Explainability** | ‚úî Good, via `feature_importances_` |\n",
    "| **Current position** | üèÜ New technical leader |\n",
    "\n",
    "---\n",
    "\n",
    "üìà **Final Summary:**  \n",
    "**Gradient Boosting** offers the best balance between precision, recall, and AUC so far.  \n",
    "Although the improvements over Random Forest are small, its consistency and generalization ability make it the **new baseline model to beat** in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151fd253",
   "metadata": {},
   "source": [
    "### üî¢ Model 5 ‚Äî K-Nearest Neighbors (KNN)\n",
    "\n",
    "---\n",
    "\n",
    "üéØ What is it and why include it?\n",
    "\n",
    "**K-Nearest Neighbors (KNN)** is a distance-based classification algorithm.  \n",
    "To classify a new observation, the model **finds the *k* nearest neighbors** (using a metric such as Euclidean distance) and assigns the **most frequent class among them**.\n",
    "\n",
    "Although it‚Äôs not usually the best model for tabular data in production, it serves as an **excellent additional reference** within the comparative process.\n",
    "\n",
    "---\n",
    "\n",
    "üß† Intuition behind its operation\n",
    "\n",
    "1. The distance from a new point to all points in the dataset is calculated.  \n",
    "2. The *k* closest neighbors are selected.  \n",
    "3. The majority class among those neighbors is predicted.\n",
    "\n",
    "\\[\n",
    "\\hat{y} = \\text{mode}(y_{(k)})\n",
    "\\]\n",
    "\n",
    "The model **does not learn explicit parameters**; instead, it stores the training data and **makes decisions ‚Äúat prediction time.‚Äù**\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ Advantages of KNN\n",
    "\n",
    "| Advantage | Explanation |\n",
    "|:-----------|:-------------|\n",
    "| **‚úÖ Simple and intuitive** | Based on similarity between observations. |\n",
    "| **‚úÖ Non-parametric** | Makes no assumptions about the data distribution. |\n",
    "| **‚úÖ Captures non-linear relationships** | Can model complex decision boundaries if *k* is chosen properly. |\n",
    "| **‚úÖ Ideal for scaled data** | Prior scaling ensures fair distance comparisons between variables. |\n",
    "\n",
    "---\n",
    "\n",
    "‚ö†Ô∏è Considerations and limitations\n",
    "\n",
    "| Limitation | Explanation |\n",
    "|:-------------|:-------------|\n",
    "| **Requires prior scaling** | Distances can be distorted if variables have different magnitudes. *(Already handled in this project)* |\n",
    "| **Sensitive to noise** | Outliers can affect classification if *k* is too small. |\n",
    "| **Low interpretability** | Does not produce coefficients or rules, making it difficult to explain in clinical contexts. |\n",
    "| **High computational cost** | During prediction, it compares the new instance to all points in the dataset. |\n",
    "\n",
    "---\n",
    "\n",
    "üìò Why include it here\n",
    "\n",
    "- The dataset has already been **scaled and cleaned**, which favors KNN‚Äôs performance.  \n",
    "- It allows us to **compare a distance-based model** with tree-based and linear models.  \n",
    "- It helps assess whether the data‚Äôs structure allows classification **by patient similarity**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a86c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation of the K-Nearest Neighbors (KNN) model using cross-validation\n",
    "# KNN classifies observations based on the labels of their k nearest neighbors\n",
    "\n",
    "# Initialize the model with k=5 (a common starting point)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "\n",
    "# Define stratified cross-validation (keeps the class proportion in each fold)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metrics to evaluate\n",
    "scoring = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]\n",
    "\n",
    "# Separate predictor and target variables\n",
    "X = df_clean.drop(columns=\"HeartDisease\")\n",
    "y = df_clean[\"HeartDisease\"]\n",
    "\n",
    "# Run cross-validation\n",
    "knn_results = cross_validate(\n",
    "    estimator=knn_model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "# Convert the results to a DataFrame for detailed inspection\n",
    "knn_df = pd.DataFrame(knn_results)[\n",
    "    [\"test_accuracy\", \"test_precision\", \"test_recall\", \"test_f1\", \"test_roc_auc\"]\n",
    "]\n",
    "\n",
    "print(\"KNN Model Results (Cross-Validation):\")\n",
    "print(knn_df.round(4))\n",
    "\n",
    "# Compute and display average metrics\n",
    "print(\"\\nAverage metrics (5-fold CV):\")\n",
    "print(knn_df.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3120d3c",
   "metadata": {},
   "source": [
    "üìä **Average Metrics (Cross-Validation ‚Äî 5 folds)**\n",
    "\n",
    "| Metric | KNN | Gradient Boosting | Random Forest |\n",
    "|:---------|:----:|:----------------:|:--------------:|\n",
    "| **Accuracy** | 0.8431 | 0.8638 | 0.8627 |\n",
    "| **Precision** | 0.8331 | 0.8652 | 0.8649 |\n",
    "| **Recall** | 0.8977 | 0.8958 | 0.8938 |\n",
    "| **F1-Score** | 0.8637 | 0.8796 | 0.8783 |\n",
    "| **ROC AUC** | 0.8880 | 0.9230 | 0.9229 |\n",
    "\n",
    "---\n",
    "\n",
    "The **KNN** model performs **reasonably well but is not competitive** compared to tree-based models.\n",
    "\n",
    "- **Recall (89.8%)** ‚Üí very high, almost on par with Gradient Boosting, meaning it **effectively detects positive heart disease cases**.  \n",
    "- However, **precision and AUC** are lower, indicating that it **misclassifies more healthy patients** (more false positives).  \n",
    "- The **AUC = 0.888** shows good class separation capability but remains **below the 0.92+** achieved by ensemble models.\n",
    "\n",
    "Overall performance is **stable**, but in terms of balancing precision and discrimination, **it does not reach the level of the best models**.\n",
    "\n",
    "---\n",
    "\n",
    "üß† **General Conclusion**\n",
    "\n",
    "| Evaluation | Result |\n",
    "|:-------------|:-----------|\n",
    "| **Compared with RF/GB** | ‚ùå Inferior |\n",
    "| **Recall** | ‚úÖ Very high |\n",
    "| **Precision / AUC** | ‚ö†Ô∏è Lower |\n",
    "| **Usefulness** | üü° Non-parametric baseline |\n",
    "| **Contribution to analysis** | üîç Serves as a comparative reference but does not improve overall performance |\n",
    "\n",
    "In summary, **KNN does not outperform Random Forest or Gradient Boosting**, although it confirms the **consistency of preprocessing and scaling**, validating that the pipeline works correctly with models of different natures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343554c6",
   "metadata": {},
   "source": [
    "### üî∫ Model 6: Support Vector Machine (SVM)\n",
    "\n",
    "---\n",
    "\n",
    "üß† What is an SVM?\n",
    "\n",
    "A **Support Vector Machine (SVM)** is a supervised classification algorithm that aims to find the **optimal hyperplane** that best separates the classes in the feature space.\n",
    "\n",
    "Its core principle is to **maximize the margin** between classes ‚Äî that is, to find the plane that leaves the **largest possible distance** between the closest points of each class (called **support vectors**).\n",
    "\n",
    "---\n",
    "\n",
    "üéØ Why can it work well?\n",
    "\n",
    "| Feature | Advantage |\n",
    "|:----------|:-----------|\n",
    "| **Non-linear separation** | Thanks to *kernels*, it can learn curved decision boundaries. |\n",
    "| **Robust to overfitting** | If the classes are well separated, it maintains strong stability. |\n",
    "| **Efficient on medium-sized data** | Ideal for moderately sized datasets (like this one). |\n",
    "| **Less sensitive to noise** | Performs well when margins are clear and outliers are few. |\n",
    "\n",
    "---\n",
    "\n",
    "‚ö†Ô∏è Important considerations\n",
    "\n",
    "| Limitation | Details |\n",
    "|:-------------|:----------|\n",
    "| **üìê Data scaling** | Requires normalized or standardized data ‚Äî already handled with `RobustScaler`. |\n",
    "| **üêå Performance** | Can become slow as dataset size or dimensionality increases. |\n",
    "| **üîç Sensitive hyperparameters** | The parameters `C` (regularization) and `gamma` (kernel) strongly affect behavior. |\n",
    "| **‚ùì Low interpretability** | Does not directly provide coefficients or feature importances. |\n",
    "\n",
    "---\n",
    "\n",
    "‚öôÔ∏è RBF Kernel (Radial Basis Function)\n",
    "\n",
    "The **RBF kernel** projects data into a **high-dimensional feature space**, enabling **non-linear class separation** through smooth, flexible boundaries.\n",
    "\n",
    "It is the **most commonly used kernel in practice**, especially when linear separation is not evident.  \n",
    "In this case, it serves as an excellent choice compared to models like Logistic Regression or KNN.\n",
    "\n",
    "---\n",
    "\n",
    "üß™ Test Objective\n",
    "\n",
    "- Evaluate the **baseline performance of an SVM with an RBF kernel**.  \n",
    "- Compare it with previously evaluated models:\n",
    "  - **Linear models:** Logistic Regression  \n",
    "  - **Tree-based models:** Random Forest, Gradient Boosting  \n",
    "  - **Distance-based models:** KNN  \n",
    "\n",
    "If performance is competitive, it will be a **strong candidate for hyperparameter tuning** in the final phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513d5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation of the Support Vector Machine (SVM) model with RBF kernel\n",
    "# The SVM seeks the optimal hyperplane that separates classes by maximizing the margin between them.\n",
    "\n",
    "# Initialize the SVM model with RBF kernel and enable probability output\n",
    "svm_model = SVC(kernel=\"rbf\", probability=True, random_state=42)\n",
    "\n",
    "# Set up stratified cross-validation (keeps class proportion consistent)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define evaluation metrics\n",
    "scoring = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]\n",
    "\n",
    "# Separate predictor variables and target variable\n",
    "X = df_clean.drop(columns=\"HeartDisease\")\n",
    "y = df_clean[\"HeartDisease\"]\n",
    "\n",
    "# Run cross-validation\n",
    "svm_results = cross_validate(\n",
    "    estimator=svm_model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "# Convert results to a DataFrame for easier interpretation\n",
    "svm_df = pd.DataFrame(svm_results)[\n",
    "    [\"test_accuracy\", \"test_precision\", \"test_recall\", \"test_f1\", \"test_roc_auc\"]\n",
    "]\n",
    "\n",
    "# Results for each fold\n",
    "print(\"SVM Model Results (5-Fold Cross-Validation):\")\n",
    "print(svm_df.round(4))\n",
    "\n",
    "# Compute average metrics to evaluate overall performance\n",
    "print(\"\\nAverage metrics:\")\n",
    "print(svm_df.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1aceea",
   "metadata": {},
   "source": [
    "üî∫ **Evaluation: Support Vector Machine (SVM with RBF)**\n",
    "\n",
    "---\n",
    "\n",
    "üìä **Average Metrics (Cross-Validation ‚Äî 5 folds)**\n",
    "\n",
    "| Metric | SVM | Gradient Boosting | Random Forest |\n",
    "|:---------|:----:|:----------------:|:--------------:|\n",
    "| **Accuracy** | 0.8595 | 0.8638 | 0.8627 |\n",
    "| **Precision** | 0.8509 | 0.8652 | 0.8649 |\n",
    "| **Recall** | 0.9056 | 0.8958 | 0.8938 |\n",
    "| **F1-Score** | 0.8770 | 0.8796 | 0.8783 |\n",
    "| **ROC AUC** | 0.9175 | 0.9230 | 0.9229 |\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ **Interpretation**\n",
    "\n",
    "The **SVM with RBF kernel** shows an **outstanding and well-balanced performance**, standing out particularly in **recall (90.6%)**, the highest among all models tested so far.  \n",
    "This means the model **detects most of the positive heart disease cases**, a critical characteristic in medical contexts.\n",
    "\n",
    "- **AUC = 0.9175**, very strong and only slightly below the ensemble models.  \n",
    "- **Slightly lower precision** (85.1%) indicates it **produces more false positives**, which is an acceptable trade-off when prioritizing sensitivity.  \n",
    "- **High F1-score (0.877)** confirms a solid balance between precision and recall.  \n",
    "\n",
    "Overall, performance is **very competitive**, proving that SVM can rival more complex models like Random Forest and Gradient Boosting.\n",
    "\n",
    "---\n",
    "\n",
    "üß™ **Conclusion**\n",
    "\n",
    "| Aspect | Evaluation |\n",
    "|:----------|:-------------|\n",
    "| **Sensitivity (Recall)** | ‚úÖ Excellent ‚Äî best in the group |\n",
    "| **Precision / AUC** | ‚öñÔ∏è Very good, slightly below GB |\n",
    "| **Interpretability** | üîç Limited compared to tree-based models |\n",
    "| **Overall performance** | üí™ Very competitive, podium guaranteed |\n",
    "\n",
    "üìå **SVM stands as a strong alternative to the leading model**, ideal for scenarios where **detecting positives is more important than avoiding false positives**, such as in early heart disease prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fd3a57",
   "metadata": {},
   "source": [
    "### üåê Model 7: Bayesian Network (Naive Bayes)\n",
    "\n",
    "---\n",
    "\n",
    "üß† **What is a Bayesian Network?**\n",
    "\n",
    "A **Bayesian Network** is a probabilistic model that represents dependencies between variables using a **directed acyclic graph (DAG)** and applies **Bayes‚Äô theorem** to perform inference on conditional probabilities.\n",
    "\n",
    "However, this full approach is complex ‚Äî and not the one we‚Äôll use here.\n",
    "\n",
    "---\n",
    "\n",
    "üßÆ **In this context: Naive Bayes**\n",
    "\n",
    "Within the `scikit-learn` library, the most practical Bayesian-like model is **Naive Bayes**, a simplified version that preserves the probabilistic essence of the Bayesian approach.\n",
    "\n",
    "**Naive Bayes**:\n",
    "- Assumes that variables are **conditionally independent** given the target.\n",
    "- Uses **Bayes‚Äô theorem** to estimate the probability of class membership.\n",
    "- Is **very fast**, efficient for small datasets, and surprisingly robust as a baseline model.\n",
    "\n",
    "---\n",
    "\n",
    "ü§î **Which version of Naive Bayes are we using?**\n",
    "\n",
    "| Version | Ideal use case |\n",
    "|:----------|:---------------|\n",
    "| **GaussianNB** | Continuous variables, assumes normal distribution |\n",
    "| **MultinomialNB** | Count data (e.g., text, events) |\n",
    "| **BernoulliNB** | Binary variables (presence/absence) |\n",
    "\n",
    "‚û°Ô∏è **We choose `GaussianNB`**, because:\n",
    "- All variables are numeric and already scaled.  \n",
    "- Even though not all follow a perfect normal distribution, the model **still performs well**.  \n",
    "- We‚Äôre interested in it as a **probabilistic contrast** to deterministic models like SVM or Gradient Boosting.\n",
    "\n",
    "---\n",
    "\n",
    "üìå **Limitations**\n",
    "\n",
    "| Limitation | Description |\n",
    "|:-------------|:-------------|\n",
    "| **Conditional independence** | Assumes all variables are independent ‚Äî rarely true in practice. |\n",
    "| **Sensitivity to collinearity** | Correlated variables can degrade performance. |\n",
    "| **Interpretability** | Does not provide direct variable importance or weights. |\n",
    "| **Limited tuning capacity** | Few useful hyperparameters for optimization. |\n",
    "\n",
    "---\n",
    "\n",
    "üß™ **Objective**\n",
    "\n",
    "Evaluate whether, **despite its simplicity**, the **Naive Bayes (GaussianNB)** model can deliver a reasonable performance compared to more sophisticated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7797966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation of the Naive Bayes model (GaussianNB version)\n",
    "# This probabilistic model assumes conditional independence among variables and applies Bayes‚Äô theorem.\n",
    "\n",
    "# Initialize the Gaussian Naive Bayes model\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Define stratified cross-validation (preserves class proportions)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define evaluation metrics\n",
    "scoring = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]\n",
    "\n",
    "# Separate predictor variables (X) and target variable (y)\n",
    "X = df_clean.drop(columns=\"HeartDisease\")\n",
    "y = df_clean[\"HeartDisease\"]\n",
    "\n",
    "# Execute cross-validation\n",
    "nb_results = cross_validate(\n",
    "    estimator=nb_model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "# Convert results to a DataFrame for easier interpretation\n",
    "nb_df = pd.DataFrame(nb_results)[\n",
    "    [\"test_accuracy\", \"test_precision\", \"test_recall\", \"test_f1\", \"test_roc_auc\"]\n",
    "]\n",
    "\n",
    "# Results for each fold\n",
    "print(\"Results of Gaussian Naive Bayes model (5-Fold Cross-Validation):\")\n",
    "print(nb_df.round(4))\n",
    "\n",
    "# Average metrics (overall performance)\n",
    "print(\"\\nAverage metrics:\")\n",
    "print(nb_df.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477e753d",
   "metadata": {},
   "source": [
    "üß™ **Evaluation: Naive Bayes (GaussianNB)**\n",
    "\n",
    "---\n",
    "\n",
    "üìä **Average Metrics (Cross-Validation ‚Äî 5 folds)**\n",
    "\n",
    "| Metric | Naive Bayes | SVM | Gradient Boosting | Random Forest |\n",
    "|:---------|:-------------:|:----:|:----------------:|:--------------:|\n",
    "| **Accuracy** | 0.8344 | 0.8595 | 0.8638 | 0.8627 |\n",
    "| **Precision** | 0.8584 | 0.8509 | 0.8652 | 0.8649 |\n",
    "| **Recall** | 0.8426 | 0.9056 | 0.8958 | 0.8938 |\n",
    "| **F1-Score** | 0.8493 | 0.8770 | 0.8796 | 0.8783 |\n",
    "| **ROC AUC** | 0.9023 | 0.9175 | 0.9230 | 0.9229 |\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ **Interpretation**\n",
    "\n",
    "The **Naive Bayes (GaussianNB)** model delivers **surprisingly strong performance** given its simplicity.\n",
    "\n",
    "- **Good balance between precision and recall**, without heavily favoring any class.  \n",
    "- **AUC = 0.90**, meaning it has excellent discriminative power between healthy and diseased patients.  \n",
    "- While it doesn‚Äôt lead in any single metric, it **remains close** to the more sophisticated models.  \n",
    "- Its **speed and efficiency** make it ideal for situations with limited computational resources or time constraints.\n",
    "\n",
    "This performance demonstrates that, even with its strong assumptions (conditional independence), the model **captures the problem structure well**, thanks to a clean and well-preprocessed dataset.\n",
    "\n",
    "---\n",
    "\n",
    "üîç **Use as final model?**\n",
    "\n",
    "| Aspect | Evaluation |\n",
    "|:----------|:------------|\n",
    "| üß† **Simplicity** | Excellent ‚Äî instant setup, no complex tuning |\n",
    "| üî¢ **Performance** | Good, though below Gradient Boosting and Random Forest |\n",
    "| ‚öôÔ∏è **Interpretability** | Limited, lacks clear feature importance or coefficients |\n",
    "| ‚è±Ô∏è **Efficiency** | Extremely fast ‚Äî ideal for lightweight deployment |\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ **Conclusion:**  \n",
    "Naive Bayes is a **great probabilistic benchmark** ‚Äî simple, stable, and surprisingly effective.  \n",
    "However, in overall performance, **ensemble models (GB, RF)** remain the **best candidates for production**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f794ca5b",
   "metadata": {},
   "source": [
    "### üß† Model 8: MLPClassifier (Feedforward Neural Network)\n",
    "\n",
    "---\n",
    "\n",
    "üî¨ What is an MLP?\n",
    "\n",
    "The **MLPClassifier (Multi-Layer Perceptron)** implements a **multilayer artificial neural network**, also called a **dense network** or **multilayer perceptron**.  \n",
    "Each neuron connects with all neurons in the next layer (**fully connected**), and the network learns the weights through the **backpropagation** algorithm.\n",
    "\n",
    "It is one of the most classic supervised neural network models, widely used for tabular, image, and structured text classification.\n",
    "\n",
    "---\n",
    "\n",
    "üß± Basic architecture\n",
    "\n",
    "The MLP has three types of layers:\n",
    "\n",
    "1. **Input layer:** receives the dataset variables (features).  \n",
    "2. **Hidden layers:** process nonlinear combinations through activation functions (default: *ReLU*).  \n",
    "3. **Output layer:** generates the final probabilities or classes.\n",
    "\n",
    "By default in `scikit-learn`, the initial architecture is:\n",
    "\n",
    "```python\n",
    "hidden_layer_sizes = (100,)\n",
    "```\n",
    "\n",
    "This means **one hidden layer with 100 neurons**.\n",
    "\n",
    "---\n",
    "\n",
    "üìå Main characteristics\n",
    "\n",
    "| Attribute | Detail |\n",
    "|:----------|:----------|\n",
    "| üî¢ **Data type** | Requires numerical and preferably scaled variables (‚úî already done). |\n",
    "| ‚öôÔ∏è **Scaling** | Mandatory for proper gradient convergence. |\n",
    "| üß† **Modeling capacity** | Captures complex and nonlinear relationships. |\n",
    "| üê¢ **Performance** | Slower than linear or tree-based models, especially with large networks. |\n",
    "| üéØ **Critical tuning** | Sensitive to hyperparameters (number of layers, neurons, learning rate, regularization). |\n",
    "| üìâ **Interpretability** | Very low without tools like SHAP or LIME. |\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ Why include it?\n",
    "\n",
    "- Adds a model of a **completely different nature** compared to the previous ones.  \n",
    "- Allows evaluation of **nonlinear interactions** that trees or linear models might not capture.  \n",
    "- Serves as a **conceptual bridge to more complex deep learning models**.\n",
    "\n",
    "---\n",
    "\n",
    "‚ö†Ô∏è Important considerations\n",
    "\n",
    "| Limitation | Implication |\n",
    "|:-------------|:-------------|\n",
    "| üíæ **Not ideal for small tabular datasets** | Boosting models usually outperform it. |\n",
    "| üßÆ **Needs fine-tuning** | Its performance strongly depends on architecture and parameters. |\n",
    "| üìä **No direct interpretability** | Requires external tools to explain decisions. |\n",
    "\n",
    "---\n",
    "\n",
    "üìö **Preliminary conclusion:**\n",
    "\n",
    "Although the **MLPClassifier** is not usually the best performer on tabular datasets, **its inclusion adds algorithmic diversity** and allows comparison of how a pure neural model behaves versus boosting or traditional ensemble methods.\n",
    "\n",
    "It will be a key test to verify whether **deep nonlinear patterns** exist in the data that other algorithms are not capturing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e130b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation of the MLPClassifier model (Feedforward Neural Network)\n",
    "# A network with one hidden layer of 100 neurons and ReLU activation function (default) is used.\n",
    "\n",
    "# Model initialization\n",
    "mlp_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),  # one hidden layer with 100 neurons\n",
    "    max_iter=1000,              # maximum number of iterations to ensure convergence\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Definition of stratified cross-validation (maintains class proportion)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluation metrics to calculate\n",
    "scoring = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]\n",
    "\n",
    "# Separation of predictor variables (X) and target variable (y)\n",
    "X = df_clean.drop(columns=\"HeartDisease\")\n",
    "y = df_clean[\"HeartDisease\"]\n",
    "\n",
    "# Execution of cross-validation\n",
    "mlp_results = cross_validate(\n",
    "    estimator=mlp_model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "# Conversion to DataFrame for result analysis\n",
    "mlp_df = pd.DataFrame(mlp_results)[\n",
    "    [\"test_accuracy\", \"test_precision\", \"test_recall\", \"test_f1\", \"test_roc_auc\"]\n",
    "]\n",
    "\n",
    "# Individual results for each fold\n",
    "print(\"üìã Results of the MLPClassifier model (5-Fold Cross-Validation):\")\n",
    "print(mlp_df.round(4))\n",
    "\n",
    "# Average metrics (overall average performance)\n",
    "print(\"\\nAverage metrics:\")\n",
    "print(mlp_df.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d5a87",
   "metadata": {},
   "source": [
    "üß† Evaluation: Neural Network (MLPClassifier)\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ **Conclusion**\n",
    "\n",
    "The performance of the **MLPClassifier** model is **adequate but not outstanding**.  \n",
    "Its metrics remain **consistent and reasonably balanced**, although below those of the ensemble models and the SVM.\n",
    "\n",
    "- **Precision and recall** around 85% ‚Üí good balance, but not reaching the best models.  \n",
    "- **AUC of 0.8936** ‚Üí good discrimination ability, though clearly lower than Gradient Boosting (0.923).  \n",
    "- No evident overfitting, but it also fails to capture complex interactions in tabular data.  \n",
    "\n",
    "üß© **General interpretation:**  \n",
    "The MLP provides solid performance, but **does not surpass boosting or ensemble models**.  \n",
    "Its inclusion, however, allows comparison of a neural-based model against classic tabular approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67052243",
   "metadata": {},
   "source": [
    "### ‚úÖ Final Model Comparison (Cross-Validation Average)\n",
    "\n",
    "---\n",
    "\n",
    "| Model | Accuracy | Precision | Recall | F1 | AUC |\n",
    "|:-----------------------|:---------:|:-----------:|:-----------:|:-----------:|:-----------:|\n",
    "| **Gradient Boosting** | **0.8638** | **0.8652** | 0.8958 | **0.8796** | **0.9230** |\n",
    "| **Random Forest** | 0.8627 | 0.8649 | 0.8938 | 0.8783 | 0.9229 |\n",
    "| **SVM (RBF)** | 0.8595 | 0.8509 | **0.9056** | 0.8770 | 0.9175 |\n",
    "| **Logistic Regression** | 0.8475 | 0.8526 | 0.8781 | 0.8641 | 0.9129 |\n",
    "| **Naive Bayes (Gaussian)** | 0.8344 | 0.8584 | 0.8426 | 0.8493 | 0.9023 |\n",
    "| **KNN** | 0.8431 | 0.8331 | 0.8977 | 0.8637 | 0.8880 |\n",
    "| **MLPClassifier** | 0.8279 | 0.8418 | 0.8525 | 0.8457 | 0.8936 |\n",
    "| **Decision Tree** | 0.7723 | 0.7990 | 0.7874 | 0.7928 | 0.7705 |\n",
    "\n",
    "---\n",
    "\n",
    "üîç **Results Analysis**\n",
    "\n",
    "- ü•á **Gradient Boosting**  \n",
    "  - Leader in **Accuracy, Precision, F1, and AUC**.  \n",
    "  - Also maintains a **very high Recall**, indicating excellent ability to detect positive cases.  \n",
    "  - Positioned as the **most balanced and reliable model** for this problem.\n",
    "\n",
    "- ü•à **Random Forest**  \n",
    "  - Very close across all metrics.  \n",
    "  - Less prone to overfitting and highly interpretable via *feature importance*.\n",
    "\n",
    "- ü•â **SVM (RBF)**  \n",
    "  - Excels in **Recall (90.6%)**, making it very sensitive to positives.  \n",
    "  - Slightly lower in other metrics but remains a competitive model.\n",
    "\n",
    "The remaining models show acceptable performance, though they do not surpass the top three.  \n",
    "In particular, **Naive Bayes** and **Logistic Regression** maintain solid and consistent results, while **MLP** and **Decision Tree** rank lower overall.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ **Final Decision**\n",
    "\n",
    "| Role | Model | Justification |\n",
    "|:------|:---------|:----------------|\n",
    "| üèÜ **Main Model** | **Gradient Boosting** | Best overall balance across all metrics. |\n",
    "| ü•à **Secondary Model** | **Random Forest** | Robust, stable, and explainable model. |\n",
    "\n",
    "---\n",
    "\n",
    "üß≠ **Next Steps**\n",
    "\n",
    "1. **Hyperparameter tuning** with `RandomizedSearchCV` on:\n",
    "   - `GradientBoostingClassifier`\n",
    "   - `RandomForestClassifier`\n",
    "\n",
    "2. **Optimization of key parameters:**\n",
    "   - Number of trees (`n_estimators`)\n",
    "   - Depth (`max_depth`)\n",
    "   - Learning rate (`learning_rate`)\n",
    "   - Subsampling (`subsample`)\n",
    "\n",
    "3. **Post-tuning evaluation** ‚Üí the **final model** will be selected based on the best average performance (AUC + F1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e392c9c3",
   "metadata": {},
   "source": [
    "## üß™ Phase 5: Hyperparameter Tuning and Optimal Model Selection\n",
    "\n",
    "üîç Why tune hyperparameters?\n",
    "\n",
    "When we train models such as trees, forests, or neural networks, **there isn‚Äôt a single ‚Äúdefined‚Äù model** ‚Äî there are many possible versions depending on how you configure their hyperparameters.\n",
    "\n",
    "These hyperparameters define aspects such as:\n",
    "\n",
    "- How many trees to use  \n",
    "- The maximum depth a tree can have  \n",
    "- How much regularization to apply  \n",
    "- The learning rate used (in Boosting)\n",
    "\n",
    "üëâ A model can go from mediocre to excellent just by choosing these parameters well.\n",
    "\n",
    "---\n",
    "\n",
    "üéõÔ∏è What is a hyperparameter?\n",
    "\n",
    "They are the **parameters you define before training the model.**  \n",
    "Unlike internal parameters, **they are not learned ‚Äî you choose them.**\n",
    "\n",
    "| Model | Hyperparameter | What it controls |\n",
    "|--------|----------------|------------------|\n",
    "| Random Forest | `n_estimators` | Number of trees in the forest |\n",
    "| Random Forest | `max_depth` | Maximum depth of the trees |\n",
    "| Gradient Boosting | `learning_rate` | How much each iteration advances |\n",
    "| Gradient Boosting | `subsample` | Percentage of data each tree uses for training |\n",
    "| All | `min_samples_split` | Minimum number of samples required to split a node |\n",
    "\n",
    "---\n",
    "\n",
    "üß™ How do we search for the best hyperparameters?\n",
    "\n",
    "We could try combinations manually, but that would be inefficient.  \n",
    "Instead, we use an automatic search process called:\n",
    "\n",
    "---\n",
    "\n",
    "‚öôÔ∏è RandomizedSearchCV ‚Äî What is it and how does it work?\n",
    "\n",
    "‚úîÔ∏è It‚Äôs a hyperparameter search technique that:\n",
    "\n",
    "- Tests **random combinations** of hyperparameters  \n",
    "- **Evaluates each combination** using cross-validation (CV)  \n",
    "- **Keeps the one with the best selected metric**  \n",
    "\n",
    "---\n",
    "\n",
    "üéõÔ∏è Why Random and not Grid?\n",
    "\n",
    "| Method | Advantages | Disadvantages |\n",
    "|---------|-------------|----------------|\n",
    "| GridSearchCV | Explores all combinations | Very slow with many variables |\n",
    "| RandomSearchCV | Randomly explores `n_iter` combos | Much faster, sufficient if the range is well chosen |\n",
    "\n",
    "**Example:**\n",
    "\n",
    "If you have 5 values for 4 hyperparameters:\n",
    "\n",
    "- GridSearch: tests 5‚Å¥ = **625 combinations**  \n",
    "- RandomSearch (with `n_iter=30`): tests only **30 combinations** ‚Üí faster, almost as effective\n",
    "\n",
    "---\n",
    "\n",
    "üß™ How are those combinations evaluated?\n",
    "\n",
    "We use **stratified cross-validation (`StratifiedKFold`)** to ensure that:\n",
    "\n",
    "- Each parameter combination is evaluated with **5 different folds** of the training set  \n",
    "- Each fold maintains the **same class proportion** (0 vs. 1)  \n",
    "- The evaluation metric is always the same: **ROC AUC**\n",
    "\n",
    "---\n",
    "\n",
    "üéØ Why use ROC AUC as the metric?\n",
    "\n",
    "Because **ROC AUC (Area Under the Curve)**:\n",
    "\n",
    "- Evaluates the **model‚Äôs ability to distinguish between classes**\n",
    "- **Does not depend on a fixed threshold** like accuracy does  \n",
    "- Is more **robust on imbalanced datasets**\n",
    "- Is the **standard metric** for binary classification tasks where the quality of probability ranking is important\n",
    "\n",
    "---\n",
    "\n",
    "üì¶ Which models will we tune?\n",
    "\n",
    "1. üî• Gradient Boosting\n",
    "\n",
    "An ensemble technique that:\n",
    "\n",
    "- Trains trees sequentially  \n",
    "- Each tree tries to **correct the errors of the previous one**  \n",
    "- Is sensitive to `learning_rate` and `max_depth`\n",
    "\n",
    "---\n",
    "\n",
    "2. üå≤ Random Forest\n",
    "\n",
    "A robust model based on random trees:\n",
    "\n",
    "- Uses **trees in parallel** (not sequential like Boosting)  \n",
    "- Is **less sensitive to noise**, fast, and generalizes well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489fe995",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean.drop(\"HeartDisease\", axis=1)\n",
    "y = df_clean[\"HeartDisease\"]\n",
    "\n",
    "# Stratified cross-validation\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Gradient Boosting\n",
    "# -----------------------------\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "gb_search = RandomizedSearchCV(\n",
    "    estimator=gb_model,\n",
    "    param_distributions=gb_param_grid,\n",
    "    n_iter=30,\n",
    "    cv=cv_strategy,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Random Forest\n",
    "# -----------------------------\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_search = RandomizedSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_distributions=rf_param_grid,\n",
    "    n_iter=30,\n",
    "    cv=cv_strategy,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Execution of the tuning\n",
    "# -----------------------------\n",
    "print(\"Tuning Gradient Boosting...\")\n",
    "gb_search.fit(X, y)\n",
    "\n",
    "print(\"Tuning Random Forest...\")\n",
    "rf_search.fit(X, y)\n",
    "\n",
    "# -----------------------------\n",
    "# Results\n",
    "# -----------------------------\n",
    "print(\"Best configuration for Gradient Boosting:\")\n",
    "print(gb_search.best_params_)\n",
    "\n",
    "print(\"\\nBest configuration for Random Forest:\")\n",
    "print(rf_search.best_params_)\n",
    "\n",
    "# Save the best models\n",
    "best_gb_model = gb_search.best_estimator_\n",
    "best_rf_model = rf_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d13bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the models\n",
    "best_gb_model.fit(X_train, y_train)\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and probabilities\n",
    "gb_preds = best_gb_model.predict(X_test)\n",
    "rf_preds = best_rf_model.predict(X_test)\n",
    "\n",
    "gb_probs = best_gb_model.predict_proba(X_test)[:, 1]\n",
    "rf_probs = best_rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# AUC\n",
    "gb_auc = roc_auc_score(y_test, gb_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "# Reports\n",
    "print(\"Gradient Boosting\")\n",
    "print(classification_report(y_test, gb_preds))\n",
    "print(\"AUC:\", gb_auc)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(classification_report(y_test, rf_preds))\n",
    "print(\"AUC:\", rf_auc)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# ROC curves with RocCurveDisplay (called once per model)\n",
    "plt.figure(figsize=(6, 6))\n",
    "RocCurveDisplay.from_estimator(\n",
    "    best_gb_model, X_test, y_test,\n",
    "    name=f\"Gradient Boosting (AUC = {gb_auc:.2f})\",\n",
    "    ax=plt.gca()\n",
    ")\n",
    "\n",
    "RocCurveDisplay.from_estimator(\n",
    "    best_rf_model, X_test, y_test,\n",
    "    name=f\"Random Forest (AUC = {rf_auc:.2f})\",\n",
    "    ax=plt.gca()\n",
    ")\n",
    "\n",
    "# Graph aesthetics\n",
    "plt.title(\"ROC Curves - Final Models\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a066b89a",
   "metadata": {},
   "source": [
    "We save and load the model to verify that it was done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d35eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "joblib.dump(best_rf_model, 'final_random_forest_model.joblib')\n",
    "\n",
    "print(\"Random Forest model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11533897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the model later\n",
    "loaded_model = joblib.load('final_random_forest_model.joblib')\n",
    "\n",
    "# Use the loaded model\n",
    "predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dc8c65",
   "metadata": {},
   "source": [
    "## üîç Phase 6: Conclusions and Results Analysis\n",
    "\n",
    "Great. Now we move into the üß† **model explainability** stage, where we‚Äôll analyze **how and why the Random Forest model makes its decisions.**\n",
    "\n",
    "---\n",
    "üéØ Objective\n",
    "\n",
    "We want to understand:\n",
    "\n",
    "- Which **variables are most important** for the model.  \n",
    "- How **each variable influences** an individual prediction.  \n",
    "- Whether the model is **interpretable and reliable** for the clinical domain.\n",
    "\n",
    "---\n",
    "\n",
    "üß∞ Tools we will use\n",
    "\n",
    "| Tool | What it does | Why we use it |\n",
    "|-------|---------------|---------------|\n",
    "| **Feature Importances (scikit-learn)** | Global importance | Identify which variables weigh the most |\n",
    "\n",
    "---\n",
    "\n",
    "üîé Step 1: Global feature importance\n",
    "\n",
    "This gives us a general idea of **which variables the model uses the most** to make decisions.\n",
    "\n",
    "In tree-based models (such as Random Forest or Gradient Boosting), each time a variable is used to split the dataset, it contributes to improving prediction accuracy.  \n",
    "Scikit-learn allows us to quantify this contribution through the `feature_importances_` attribute.\n",
    "\n",
    "üìà **Interpretation:**\n",
    "\n",
    "- Variables with higher *feature importance* are those that contribute the most to the model.  \n",
    "- If, for example, `Cholesterol`, `Age`, or `RestingBP` appear at the top, it means the model uses them as key criteria to decide whether a patient has heart disease or not.  \n",
    "- This provides a **global and clinical perspective** on which factors are correlated with risk according to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d6bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature names\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Importances\n",
    "importances = best_rf_model.feature_importances_\n",
    "\n",
    "# Create DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"Global Feature Importance - Random Forest\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facfbc8e",
   "metadata": {},
   "source": [
    "üßæ Final Project Summary\n",
    "\n",
    "---\n",
    "\n",
    "üéØ Project Objective\n",
    "\n",
    "The goal of this project was to **build a classification model capable of predicting the presence of heart disease in patients**, using collected clinical data.  \n",
    "The objective was not only to achieve **high predictive performance**, but also to follow a **rigorous methodology** that would allow for:\n",
    "\n",
    "- Clear interpretation of the results  \n",
    "- Full reproducibility of the process  \n",
    "- Preparation of the model for evaluation in a real-world setting  \n",
    "\n",
    "---\n",
    "\n",
    "üß™ Applied Methodology\n",
    "\n",
    "Throughout the analysis, a standard **data science workflow** was followed, structured in the following phases:\n",
    "\n",
    "1. **Dataset loading and initial review**  \n",
    "2. **Exploratory Data Analysis (EDA)** ‚Äî univariate and bivariate  \n",
    "3. **Data cleaning and treatment** of missing and outlier values  \n",
    "4. **Statistical transformations** and feature scaling  \n",
    "5. **Categorical variable encoding**  \n",
    "6. **Stratified data splitting** into training and test sets  \n",
    "7. **Training of multiple classification models**  \n",
    "8. **Evaluation** using cross-validation and multiple metrics  \n",
    "9. **Hyperparameter tuning** with *RandomizedSearchCV*  \n",
    "10. **Final comparison and selection** of the optimal model  \n",
    "11. **Storage** of the final trained model  \n",
    "\n",
    "---\n",
    "\n",
    "üìà Evaluated Models\n",
    "\n",
    "The following classification algorithms were trained and compared:\n",
    "\n",
    "- **Logistic Regression**  \n",
    "- **Decision Tree**  \n",
    "- **Random Forest**  \n",
    "- **Gradient Boosting**  \n",
    "- **K-Nearest Neighbors (KNN)**  \n",
    "- **Support Vector Machine (SVM)**  \n",
    "- **Naive Bayes**  \n",
    "- **Multi-Layer Perceptron (MLP)**  \n",
    "\n",
    "All models were evaluated using **stratified cross-validation**, with multiple metrics:\n",
    "\n",
    "- *Accuracy*  \n",
    "- *Precision*  \n",
    "- *Recall*  \n",
    "- *F1-score*  \n",
    "- *AUC-ROC*\n",
    "\n",
    "---\n",
    "\n",
    "ü•á Selected Model\n",
    "\n",
    "The final chosen model was **Random Forest**, after proving to be the most robust in terms of:\n",
    "\n",
    "- Higher **precision in the positive class** (presence of disease)  \n",
    "- Good **balance between recall and precision**  \n",
    "- **Consistently high AUC-ROC** during cross-validation  \n",
    "\n",
    "This model was trained with **fine hyperparameter tuning** and evaluated on the test set, confirming its performance.  \n",
    "Finally, it was saved for future reuse or deployment.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ Conclusion\n",
    "\n",
    "A **solid and interpretable predictive model** has been developed through a complete process that included:\n",
    "\n",
    "- A thorough exploratory analysis and data cleaning  \n",
    "- Proper handling of numerical and categorical variables  \n",
    "- A rigorous comparison of algorithms and validation techniques  \n",
    "\n",
    "The work carried out provides a **reliable and reproducible foundation** for tackling similar problems in the clinical field, standing out for its **structured approach, interpretability, and statistical consistency.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
